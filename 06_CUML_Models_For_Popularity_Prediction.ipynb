{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Setup"
      ],
      "metadata": {
        "id": "RZ7GEuUIrlWg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UmyxGNv2ijMD"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.0-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "T3T_HHcZL5Px",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c0b7290-e9a8-4e45-96f4-e6a88cac51c6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed May  3 00:42:24 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0    40W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This get the RAPIDS-Colab install files and test check your GPU.  Run this and the next cell only.\n",
        "# Please read the output of this cell.  If your Colab Instance is not RAPIDS compatible, it will warn you and give you remediation steps.\n",
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!python rapidsai-csp-utils/colab/pip-install.py"
      ],
      "metadata": {
        "id": "kMm_tXE7Mcmm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0ad78af-1fc0-4fd3-f44b-0307ba9fadb4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'rapidsai-csp-utils'...\n",
            "remote: Enumerating objects: 385, done.\u001b[K\n",
            "remote: Counting objects: 100% (116/116), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 385 (delta 86), reused 51 (delta 51), pack-reused 269\u001b[K\n",
            "Receiving objects: 100% (385/385), 105.74 KiB | 341.00 KiB/s, done.\n",
            "Resolving deltas: 100% (188/188), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pynvml\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.1/53.1 kB 2.4 MB/s eta 0:00:00\n",
            "Installing collected packages: pynvml\n",
            "Successfully installed pynvml-11.5.0\n",
            "***********************************************************************\n",
            "Woo! Your instance has the right kind of GPU, a NVIDIA A100-SXM4-40GB!\n",
            "We will now install RAPIDS cuDF, cuML, and cuGraph via pip! \n",
            "Please stand by, should be quick...\n",
            "***********************************************************************\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://pypi.nvidia.com\n",
            "Collecting cudf-cu11\n",
            "  Downloading https://pypi.nvidia.com/cudf-cu11/cudf_cu11-23.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (496.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 496.6/496.6 MB 2.5 MB/s eta 0:00:00\n",
            "Collecting cuml-cu11\n",
            "  Downloading https://pypi.nvidia.com/cuml-cu11/cuml_cu11-23.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1110.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 GB 1.5 MB/s eta 0:00:00\n",
            "Collecting cugraph-cu11\n",
            "  Downloading https://pypi.nvidia.com/cugraph-cu11/cugraph_cu11-23.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1142.4 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 GB 1.5 MB/s eta 0:00:00\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 13.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from cudf-cu11) (4.5.0)\n",
            "Collecting cuda-python<12.0,>=11.7.1\n",
            "  Downloading cuda_python-11.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.5/16.5 MB 64.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pandas<1.6.0dev0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11) (1.22.4)\n",
            "Collecting pyarrow==10.*\n",
            "  Downloading pyarrow-10.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 35.9/35.9 MB 48.9 MB/s eta 0:00:00\n",
            "Collecting rmm-cu11==23.4.*\n",
            "  Downloading https://pypi.nvidia.com/rmm-cu11/rmm_cu11-23.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 MB 84.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11) (2023.4.0)\n",
            "Collecting nvtx>=0.2.1\n",
            "  Downloading nvtx-0.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (428 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 428.4/428.4 kB 45.2 MB/s eta 0:00:00\n",
            "Collecting cubinlinker-cu11\n",
            "  Downloading https://pypi.nvidia.com/cubinlinker-cu11/cubinlinker_cu11-0.3.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.8/8.8 MB 107.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from cudf-cu11) (23.1)\n",
            "Requirement already satisfied: numba<0.57,>=0.56.4 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11) (0.56.4)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from cudf-cu11) (5.3.0)\n",
            "Collecting protobuf<4.22,>=4.21.6\n",
            "  Downloading protobuf-4.21.12-cp37-abi3-manylinux2014_x86_64.whl (409 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 409.8/409.8 kB 42.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: cupy-cuda11x<12.0.0a0,>=9.5.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11) (11.0.0)\n",
            "Collecting ptxcompiler-cu11\n",
            "  Downloading https://pypi.nvidia.com/ptxcompiler-cu11/ptxcompiler_cu11-0.7.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.8/8.8 MB 120.4 MB/s eta 0:00:00\n",
            "Collecting treelite-runtime==3.2.0\n",
            "  Downloading treelite_runtime-3.2.0-py3-none-manylinux2014_x86_64.whl (198 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 198.2/198.2 kB 26.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (1.2.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (1.10.1)\n",
            "Collecting dask-cudf-cu11==23.4.*\n",
            "  Downloading https://pypi.nvidia.com/dask-cudf-cu11/dask_cudf_cu11-23.4.1-py3-none-any.whl (79 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.4/79.4 kB 12.3 MB/s eta 0:00:00\n",
            "Collecting dask==2023.3.2\n",
            "  Downloading dask-2023.3.2-py3-none-any.whl (1.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 78.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (0.12.2)\n",
            "Collecting treelite==3.2.0\n",
            "  Downloading treelite-3.2.0-py3-none-manylinux2014_x86_64.whl (1.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 77.6 MB/s eta 0:00:00\n",
            "Collecting raft-dask-cu11==23.4.*\n",
            "  Downloading https://pypi.nvidia.com/raft-dask-cu11/raft_dask_cu11-23.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (215.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 215.1/215.1 MB 4.9 MB/s eta 0:00:00\n",
            "Collecting distributed==2023.3.2.1\n",
            "  Downloading distributed-2023.3.2.1-py3-none-any.whl (957 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 957.1/957.1 kB 72.1 MB/s eta 0:00:00\n",
            "Collecting dask-cuda==23.4.*\n",
            "  Downloading dask_cuda-23.4.0-py3-none-any.whl (125 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 125.3/125.3 kB 16.8 MB/s eta 0:00:00\n",
            "Collecting importlib-metadata>=4.13.0\n",
            "  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from dask==2023.3.2->cuml-cu11) (2.2.1)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask==2023.3.2->cuml-cu11) (1.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask==2023.3.2->cuml-cu11) (6.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from dask==2023.3.2->cuml-cu11) (0.12.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from dask==2023.3.2->cuml-cu11) (8.1.3)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from dask-cuda==23.4.*->cuml-cu11) (3.0.0)\n",
            "Collecting pynvml<11.5,>=11.0.0\n",
            "  Downloading pynvml-11.4.1-py3-none-any.whl (46 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.0/47.0 kB 6.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (2.4.0)\n",
            "Requirement already satisfied: psutil>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (5.9.5)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (3.1.2)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (1.0.0)\n",
            "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (6.2)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (1.7.0)\n",
            "Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (1.26.15)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (1.0.5)\n",
            "Collecting ucx-py-cu11==0.31.*\n",
            "  Downloading https://pypi.nvidia.com/ucx-py-cu11/ucx_py_cu11-0.31.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.3/8.3 MB 110.4 MB/s eta 0:00:00\n",
            "Collecting pylibraft-cu11==23.4.*\n",
            "  Downloading https://pypi.nvidia.com/pylibraft-cu11/pylibraft_cu11-23.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (618.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 618.0/618.0 MB 1.9 MB/s eta 0:00:00\n",
            "Collecting pylibcugraph-cu11==23.4.*\n",
            "  Downloading https://pypi.nvidia.com/pylibcugraph-cu11/pylibcugraph_cu11-23.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1141.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 GB 1.5 MB/s eta 0:00:00\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 268.8/268.8 kB 31.7 MB/s eta 0:00:00\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (2.0.12)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 149.6/149.6 kB 20.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (23.1.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.5/114.5 kB 15.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from cuda-python<12.0,>=11.7.1->cudf-cu11) (0.29.34)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda11x<12.0.0a0,>=9.5.0->cudf-cu11) (0.8.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba<0.57,>=0.56.4->cudf-cu11) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba<0.57,>=0.56.4->cudf-cu11) (67.7.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6.0dev0,>=1.3->cudf-cu11) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6.0dev0,>=1.3->cudf-cu11) (2.8.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp) (3.4)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn->cuml-cu11) (3.7.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask==2023.3.2->cuml-cu11) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.10.3->distributed==2023.3.2.1->cuml-cu11) (2.1.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->cuml-cu11) (4.39.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->cuml-cu11) (8.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->cuml-cu11) (1.0.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->cuml-cu11) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->cuml-cu11) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->cuml-cu11) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<1.6.0dev0,>=1.3->cudf-cu11) (1.16.0)\n",
            "Installing collected packages: ptxcompiler-cu11, nvtx, cubinlinker-cu11, pynvml, pyarrow, protobuf, multidict, importlib-metadata, frozenlist, cuda-python, async-timeout, yarl, ucx-py-cu11, treelite-runtime, treelite, rmm-cu11, dask, aiosignal, pylibraft-cu11, distributed, cudf-cu11, aiohttp, pylibcugraph-cu11, dask-cudf-cu11, dask-cuda, raft-dask-cu11, cuml-cu11, cugraph-cu11\n",
            "  Attempting uninstall: pynvml\n",
            "    Found existing installation: pynvml 11.5.0\n",
            "    Uninstalling pynvml-11.5.0:\n",
            "      Successfully uninstalled pynvml-11.5.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 9.0.0\n",
            "    Uninstalling pyarrow-9.0.0:\n",
            "      Successfully uninstalled pyarrow-9.0.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2022.12.1\n",
            "    Uninstalling dask-2022.12.1:\n",
            "      Successfully uninstalled dask-2022.12.1\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 2022.12.1\n",
            "    Uninstalling distributed-2022.12.1:\n",
            "      Successfully uninstalled distributed-2022.12.1\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.17.9 requires pyarrow<10.0dev,>=3.0.0, but you have pyarrow 10.0.1 which is incompatible.\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 cubinlinker-cu11-0.3.0.post1 cuda-python-11.8.1 cudf-cu11-23.4.1 cugraph-cu11-23.4.1 cuml-cu11-23.4.1 dask-2023.3.2 dask-cuda-23.4.0 dask-cudf-cu11-23.4.1 distributed-2023.3.2.1 frozenlist-1.3.3 importlib-metadata-6.6.0 multidict-6.0.4 nvtx-0.2.5 protobuf-4.21.12 ptxcompiler-cu11-0.7.0.post1 pyarrow-10.0.1 pylibcugraph-cu11-23.4.1 pylibraft-cu11-23.4.1 pynvml-11.4.1 raft-dask-cu11-23.4.1 rmm-cu11-23.4.1 treelite-3.2.0 treelite-runtime-3.2.0 ucx-py-cu11-0.31.1 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cupy-cuda11x in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda11x) (0.8.1)\n",
            "Requirement already satisfied: numpy<1.26,>=1.20 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda11x) (1.22.4)\n",
            "\n",
            "          ***********************************************************************\n",
            "          The pip install of RAPIDS is complete.\n",
            "          \n",
            "          Please do not run any further installation from the conda based installation methods, as they may cause issues!  \n",
            "          \n",
            "          Please ensure that you're pulling from the git repo to remain updated with the latest working install scripts. \n",
            "r          \n",
            "          Troubleshooting:\n",
            "             - If there is an installation failure, please check back on RAPIDSAI owned templates/notebooks to see how to update your personal files. \n",
            "             - If an installation failure persists when using the latest script, please make an issue on https://github.com/rapidsai-community/rapidsai-csp-utils\n",
            "          ***********************************************************************\n",
            "          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "38GsCdSRix-u"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"spark-3.2.0-bin-hadoop3.2\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "import cudf, io, cuml\n",
        "import cupy as cp\n",
        "\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, pandas_udf, PandasUDFType\n",
        "from pyspark.sql.types import StructType, StructField, DoubleType, LongType\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"rapids\").getOrCreate()"
      ],
      "metadata": {
        "id": "PlPD2DhsJwcf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "u8yU4NRQo015",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0775daa-afa4-46b1-ac1b-f4ab06dd96f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2Q1Eh4JS02ku"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import explode, split, lower, regexp_replace, count, when, col\n",
        "\n",
        "from cuml.svm import SVC, LinearSVC\n",
        "from cuml.metrics import accuracy_score, mean_squared_error, confusion_matrix, mean_absolute_error\n",
        "from cuml.model_selection import GridSearchCV\n",
        "from cuml.linear_model import Ridge, Lasso, LinearRegression\n",
        "from cuml.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preperation"
      ],
      "metadata": {
        "id": "gMq5Cu5Prr7U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "10VPirKh3suu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecd115f4-214f-43f6-a25b-46857d2c1bfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+------------------------+--------------------+--------------------+--------------+--------------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+-----------+--------+-------+----+-------+----------+----------------+--------------+------------+-------------+------------+------------+---------+--------------------+\n",
            "|            track_id|          track_name|        track_artist|track_popularity|      track_album_id|    track_album_name|track_album_release_date|       playlist_name|         playlist_id|playlist_genre|   playlist_subgenre|danceability|energy|key|loudness|mode|speechiness|acousticness|instrumentalness|liveness|valence|  tempo|duration_ms|language|genreID|year|minutes|word_count|words_per_minute|repetition_pct|stopword_pct|profanity_pct|negative_pct|positive_pct|Sentiment|   words_only_lyrics|\n",
            "+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+------------------------+--------------------+--------------------+--------------+--------------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+-----------+--------+-------+----+-------+----------+----------------+--------------+------------+-------------+------------+------------+---------+--------------------+\n",
            "|0EDQwboQDmswDRn58...|            Kingston|        Faye Webster|              59|4vt0V1SmkaK1Y440P...|Atlanta Millionai...|               5/24/2019|Ultimate Indie Pr...|37i9dQZF1DWTc5QDl...|           r&b|             hip pop|        0.73| 0.344| 10|  -9.541|   0|     0.0394|       0.138|         0.00128|   0.134|  0.543|142.129|     202160|      en|      2|2010|    3.4|       220|              64|          0.72|        0.42|          0.0|        0.01|        0.01|        2|The day that I me...|\n",
            "|0HaAoQJ1PgF0gIm1o...|Where Them Niggaz...|         Pastor Troy|               9|5almm5i3TH8NFWo1M...|    Face Off Part II|                3/1/2005|    Southern Hip Hop|57sYMLFXGD4Zqizzc...|           rap|    southern hip hop|       0.809| 0.866|  6|  -5.221|   0|      0.254|     0.00672|               0|    0.12|  0.558|142.102|     213053|      en|      3|2000|    3.6|       380|             105|          0.55|        0.28|         0.08|        0.09|        0.01|        0|This that hard sh...|\n",
            "|0i3utbege8Iy3q7Hy...|Klanga - De Hofna...|              Gostan|               5|4rcRFEkfAeLD4GMhe...|              Klanga|              11/28/2014|Chillout & Remixe...|4NlAd9NpIa92IjErM...|           pop|     indie poptimism|       0.719| 0.527|  6|  -9.077|   1|     0.0408|      0.0312|           0.716|   0.105|   0.58|123.955|     264293|      en|      1|2010|    4.4|       105|              23|          0.55|         0.3|         0.01|        0.01|        0.02|        2|Two thousand year...|\n",
            "|0IXpUl1fn2QZcBavf...|Living After Midn...|        Judas Priest|              63|5bqtZRbUZUxUps8mr...|       British Steel|                    1980|Workday: Rock Cla...|37i9dQZF1DX1lwxXv...|          rock|        classic rock|        0.61| 0.824|  4|  -6.046|   1|     0.0534|      0.0136|        1.75E-06|  0.0606|  0.819|134.992|     210133|      en|      0|1980|    3.5|       340|              97|           0.8|        0.25|          0.0|        0.01|        0.04|        2|Living after midn...|\n",
            "|0ooy3NjwsJreceWYC...|Never Let Me Down...|        Depeche Mode|              10|5Yyx661Ksxl2pmRUu...|Music for the Masses|               9/28/1987|Maxi Pop  GOLD (N...|2nRWtTI9a2LWjJ9Wy...|           pop|          electropop|       0.599| 0.719|  0|  -12.57|   1|     0.0288|       0.281|          0.0514|   0.693|  0.785| 106.08|     288000|      en|      1|1980|    4.8|       231|              48|          0.81|        0.38|          0.0|         0.0|        0.02|        2|Im taking a ride ...|\n",
            "|0QyIxB3MqUoSQX0kB...|Sweet Emotion - S...|           Aerosmith|              39|3VNTh6evo3MyUsStA...|Aerosmith's Great...|              11/11/1980|       70s Hard Rock|6pZlZ20vt3aDjIKw9...|          rock|           hard rock|       0.473| 0.787|  2|  -9.898|   1|     0.0317|      0.0131|        8.76E-04|  0.0913|  0.603| 99.893|     192733|      en|      0|1980|    3.2|       162|              50|          0.51|        0.35|          0.0|        0.02|        0.02|        2|NA Sweet emotion ...|\n",
            "|0tVv9FxhUjHrhF1DL...|         Fuji Opener|            Skrillex|              58|6xKK037rfCf2f6gf3...|         Show Tracks|               7/19/2019|          Nasty Bits|37i9dQZF1DX2VvACC...|           edm|       electro house|       0.662| 0.941|  1|  -1.641|   1|     0.0626|    3.75E-04|           0.029|   0.292|  0.579|149.982|     167200|      en|      4|2010|    2.8|        14|               5|          0.43|        0.29|          0.0|         0.0|        0.07|        2|Pop watch me pop ...|\n",
            "|0yxWY5cPaPUpeAoqS...|         Tropic Love|            Diviners|              53|2iyxWjV2Rfe04h4uz...|         Tropic Love|               3/26/2015|          ElectroPop|0cuHKz65ZPqBX1brG...|           pop|          electropop|       0.746| 0.809|  2|  -6.429|   1|     0.0329|       0.236|        2.59E-05|   0.235|  0.493|104.989|     299440|      en|      1|2010|    5.0|       558|             111|          0.91|        0.37|          0.0|        0.02|        0.02|        1|I remember the oc...|\n",
            "|15Trb1S2FDZSMLDzW...|            Promises|     The Cranberries|              56|2v9PjvIkQVnyQdtD1...|    Bury The Hatchet|               4/19/1999|The Cranberries B...|4E3K9oQgvLcKEz0wg...|          rock|          album rock|       0.501| 0.864|  4|  -3.231|   0|     0.0502|      0.0628|               0|   0.169|  0.247|130.063|     327573|      en|      0|1990|    5.5|       355|              64|          0.79|        0.44|          0.0|        0.04|        0.03|        0|Ooh ooh ooh ohh O...|\n",
            "|1Ahp4PZ1vzdbzBCed...|             The One|         Jorja Smith|              62|3AlSuZnX4ZCab8eoW...|        Lost & Found|                6/8/2018|  urban CONTEMPORARY|1nFfDHtp8RY3obgen...|           r&b|  urban contemporary|       0.312| 0.661|  0|  -8.508|   0|      0.092|       0.252|        1.35E-04|   0.102|  0.443|  82.39|     197575|      en|      2|2010|    3.3|        69|              20|          0.45|        0.32|          0.0|        0.03|        0.04|        2|Never had to work...|\n",
            "|1KgfeuVn5OlsBEtoE...|        Live Forever|               Oasis|              57|5zfhhKXHK0YQdvacC...|    Definitely Maybe|               8/29/1994|      Permanent Wave|5glAD13obyL0G9SH9...|          rock|      permanent wave|       0.335| 0.776|  9|   -5.32|   0|     0.0325|    9.27E-06|        9.51E-06|   0.369|  0.219|  90.59|     276867|      en|      0|1990|    4.6|       252|              54|          0.81|        0.27|          0.0|        0.02|         0.0|        0|Oh yeah Maybe I d...|\n",
            "|1nHvUtf7NJBH1WzCh...|Calling Out - Ori...|                Dyro|               4|4IyK3VqdHW4KuKS1M...|         Calling Out|                5/5/2014|         Vocal House|5PCAWKfUWAUj8VeY8...|           edm|progressive elect...|       0.826| 0.861|  1|  -3.392|   0|       0.13|      0.0232|        4.28E-04|    0.12|   0.31|128.007|     271000|      en|      4|2010|    4.5|       128|              28|          0.84|        0.55|          0.0|        0.03|         0.0|        0|I find myself cal...|\n",
            "|1pBO9JDqh1y3TbCKE...|           Nostalgic|       A R I Z O N A|              36|1mfUDy3N3YIHDlJp4...|           Nostalgic|               6/18/2019|           Dance Pop|37i9dQZF1DWZQaaqN...|           pop|           dance pop|       0.691| 0.538|  0|  -9.952|   1|      0.103|       0.246|           0.163|   0.178|  0.329| 99.972|     182668|      en|      1|2010|    3.0|       324|             108|          0.77|        0.25|          0.0|        0.02|        0.02|        1|Okay fine maybe I...|\n",
            "|1xznGGDReH1oQq0xz...|           One Dance|               Drake|              20|3hARKC8cinq3mZLLA...|               Views|                5/6/2016|Electropop Hits  ...|7kyvBmlc1uSqsTL0E...|           pop|          electropop|       0.791| 0.619|  1|  -5.886|   1|     0.0532|     0.00784|         0.00423|   0.351|  0.371|103.989|     173987|      en|      1|2010|    2.9|      1182|             407|          0.93|        0.38|          0.0|        0.01|        0.02|        2|Baby I like your ...|\n",
            "|2BgEsaKNfHUdlh97K...|                2002|          Anne-Marie|              83|7lPoGKpCGgdKFAxpu...|Speak Your Mind (...|               4/27/2018|Intro to Post-Tee...|6o6MNYZqHSkMAKcCH...|           pop|       post-teen pop|       0.697| 0.683|  1|  -2.881|   0|      0.117|      0.0372|               0|   0.137|  0.603| 96.133|     186987|      en|      1|2010|    3.1|        57|              18|           0.4|        0.39|          0.0|         0.0|        0.05|        2|I will always rem...|\n",
            "|2C1HfPSxkTrp29qSc...| Motor City Madhouse|          Ted Nugent|              10|0n5v0O4M1D6Cw5d4K...|The Essential Ted...|              10/26/2010|       70s Hard Rock|6pZlZ20vt3aDjIKw9...|          rock|           hard rock|       0.527| 0.917|  7|  -7.368|   1|     0.0923|      0.0146|          0.0988|   0.135|  0.419|119.466|     273160|      en|      0|2010|    4.6|       194|              42|          0.68|        0.26|          0.0|        0.03|        0.03|        2|Woh welcome to my...|\n",
            "|2CRz2pMU6A46P1cK3...|          I Dare You|                Jauz|              55|6qNKTCFnFxgM1SXl1...|          I Dare You|                6/7/2019|          Nasty Bits|37i9dQZF1DX2VvACC...|           edm|       electro house|       0.634| 0.953| 10|  -2.934|   0|     0.0633|       0.195|        8.08E-05|   0.115|  0.587|130.016|     296308|      en|      4|2010|    4.9|       416|              84|          0.97|         0.4|          0.0|        0.07|         0.0|        0|I dare you to mov...|\n",
            "|2de98HzQLgj4mN9X6...|Wonderous Stories...|                 Yes|              38|2U4JHXMiBxsKH4dnY...|Going for the One...|                    1977|Progressive Rock ...|7GhTpb4eOp6403Bmg...|          rock|          album rock|       0.382| 0.605|  4|  -9.351|   1|     0.0292|       0.196|               0|  0.0994|  0.147|141.065|     229160|      en|      0|1970|    3.8|       198|              52|          0.64|        0.34|          0.0|        0.02|        0.05|        2|I awoke this morn...|\n",
            "|2fY6tqgrlrg1ky9fg...|Wanted Dead Or Alive|            Bon Jovi|              14|5uU2uM1RGHfzlA12o...|   Slippery When Wet|                1/1/1986|  Classic Rock Drive|37i9dQZF1DXdOEFt9...|          rock|        classic rock|       0.257| 0.803|  7|  -3.886|   1|     0.0411|       0.137|          0.0156|   0.297|  0.294|150.818|     308667|      en|      0|1980|    5.1|       462|              90|          0.85|         0.3|          0.0|        0.05|         0.0|        0|Its all the same ...|\n",
            "|2olVm1lHicpveMAo4...|   The Power Of Love|Huey Lewis & The ...|              72|0u34k1ANjgZ47uQfG...|Greatest Hits: Hu...|                1/1/2006|  Classic Rock Radio|4lIywN6kXl9KPm3OQ...|          rock|        classic rock|       0.768| 0.829|  5|  -5.109|   1|     0.0313|      0.0964|        2.92E-05|   0.097|  0.962|118.773|     234333|      en|      0|2000|    3.9|       294|              75|          0.69|        0.35|          0.0|        0.03|        0.09|        2|The power of love...|\n",
            "+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+------------------------+--------------------+--------------------+--------------+--------------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+-----------+--------+-------+----+-------+----------+----------------+--------------+------------+-------------+------------+------------+---------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14398"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#i have an extra folder named /H516 so my pathway might be different than yours\n",
        "lyrics_df = spark.read.csv(\"/content/drive/My Drive/Colab Notebooks/spotify_with_word_counts.csv\", header=True)\n",
        "\n",
        "lyrics_df.show()\n",
        "lyrics_df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YkmYprg0AbH-"
      },
      "outputs": [],
      "source": [
        "df_With_Extra_Columns = lyrics_df.withColumn(\"HitOrMiss\", \\\n",
        "   when(lyrics_df.track_popularity < 21, 0). \\\n",
        "   when(lyrics_df.track_popularity > 79, 2).\n",
        "    otherwise(1) \\\n",
        "  )\n",
        "\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn(\"instrumentalnessFlag\", \\\n",
        "   when(df_With_Extra_Columns.instrumentalness > .5, 1).\n",
        "    otherwise(0) \\\n",
        "  )\n",
        "\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn(\"livenessFlag\", \\\n",
        "   when(df_With_Extra_Columns.liveness > .5, 1).\n",
        "    otherwise(0) \\\n",
        "  )\n",
        "\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn(\"acousticnessFlag\", \\\n",
        "   when(df_With_Extra_Columns.acousticness > .5, 1).\n",
        "    otherwise(0) \\\n",
        "  )\n",
        "\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn(\"SpeechinessVsWordCount\", \\\n",
        "   df_With_Extra_Columns.speechiness * df_With_Extra_Columns.word_count\n",
        "  )\n",
        "\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn(\"instrumentalnessFlagVsrepetition_pct\", \\\n",
        "   df_With_Extra_Columns.instrumentalnessFlag * df_With_Extra_Columns.repetition_pct\n",
        "  )\n",
        "\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn(\"acousticnessFlagnessVsrepetition_pct\", \\\n",
        "   df_With_Extra_Columns.acousticnessFlag * df_With_Extra_Columns.repetition_pct\n",
        "  )\n",
        "\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn(\"acousticnessFlagnessVsloudness\", \\\n",
        "   df_With_Extra_Columns.acousticnessFlag * df_With_Extra_Columns.loudness\n",
        "  )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pXLz5aZ8o-xL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aff5dd9-88e2-463c-e860-f656d4cb87e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14398"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df_With_Extra_Columns.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ApJq40llhah5"
      },
      "outputs": [],
      "source": [
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('track_popularity', col('track_popularity').cast('int'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('genreID', col('genreID').cast('int'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('key', col('key').cast('int'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('mode', col('mode').cast('int'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('words_per_minute', col('words_per_minute').cast('int'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('word_count', col('word_count').cast('int'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('Sentiment', col('Sentiment').cast('int'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('danceability', col('danceability').cast('double'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('energy', col('energy').cast('double'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('loudness', col('loudness').cast('double'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('speechiness', col('speechiness').cast('double'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('acousticness', col('acousticness').cast('double'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('instrumentalness', col('instrumentalness').cast('double'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('liveness', col('liveness').cast('double'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('valence', col('valence').cast('double'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('tempo', col('tempo').cast('double'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('repetition_pct', col('repetition_pct').cast('double'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('stopword_pct', col('stopword_pct').cast('double'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('profanity_pct', col('profanity_pct').cast('double'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('minutes', col('minutes').cast('double'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('negative_pct', col('negative_pct').cast('double'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('positive_pct', col('positive_pct').cast('double'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('SpeechinessVsWordCount', col('SpeechinessVsWordCount').cast('double'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('instrumentalnessFlagVsrepetition_pct', col('instrumentalnessFlagVsrepetition_pct').cast('double'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('acousticnessFlagnessVsrepetition_pct', col('acousticnessFlagnessVsrepetition_pct').cast('double'))\n",
        "df_With_Extra_Columns = df_With_Extra_Columns.withColumn('acousticnessFlagnessVsloudness', col('acousticnessFlagnessVsloudness').cast('double'))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert PySpark DataFrame to Pandas DataFrame\n",
        "pdf_full = df_With_Extra_Columns.toPandas()\n",
        "pdf_full.convert_dtypes().dtypes\n",
        "\n",
        "#randomize the pandas dataframe\n",
        "pdf_full = pdf_full.sample(frac = 1)\n",
        "\n",
        "df_cudf_full = cudf.DataFrame.from_pandas(pdf_full)\n",
        "df_cudf_full = df_cudf_full.dropna()\n",
        "df_cudf_full.count()"
      ],
      "metadata": {
        "id": "-ECl_n4QOl_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8cd2e8f-74b5-4b16-ccc8-7ff25692b3dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "track_id                                14396\n",
              "track_name                              14396\n",
              "track_artist                            14396\n",
              "track_popularity                        14396\n",
              "track_album_id                          14396\n",
              "track_album_name                        14396\n",
              "track_album_release_date                14396\n",
              "playlist_name                           14396\n",
              "playlist_id                             14396\n",
              "playlist_genre                          14396\n",
              "playlist_subgenre                       14396\n",
              "danceability                            14396\n",
              "energy                                  14396\n",
              "key                                     14396\n",
              "loudness                                14396\n",
              "mode                                    14396\n",
              "speechiness                             14396\n",
              "acousticness                            14396\n",
              "instrumentalness                        14396\n",
              "liveness                                14396\n",
              "valence                                 14396\n",
              "tempo                                   14396\n",
              "duration_ms                             14396\n",
              "language                                14396\n",
              "genreID                                 14396\n",
              "year                                    14396\n",
              "minutes                                 14396\n",
              "word_count                              14396\n",
              "words_per_minute                        14396\n",
              "repetition_pct                          14396\n",
              "stopword_pct                            14396\n",
              "profanity_pct                           14396\n",
              "negative_pct                            14396\n",
              "positive_pct                            14396\n",
              "Sentiment                               14396\n",
              "words_only_lyrics                       14396\n",
              "HitOrMiss                               14396\n",
              "instrumentalnessFlag                    14396\n",
              "livenessFlag                            14396\n",
              "acousticnessFlag                        14396\n",
              "SpeechinessVsWordCount                  14396\n",
              "instrumentalnessFlagVsrepetition_pct    14396\n",
              "acousticnessFlagnessVsrepetition_pct    14396\n",
              "acousticnessFlagnessVsloudness          14396\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_cudf_test = df_cudf_full.head(n=3000)\n",
        "df_cudf_train = df_cudf_full.tail(n=11396)\n",
        "\n",
        "expression = \"(genreID != 3)\"\n",
        "df_cudf_No_Rap = df_cudf_full.query(expression)\n",
        "expression = \"(genreID == 3)\"\n",
        "df_cudf_Rap = df_cudf_full.query(expression)\n",
        "\n",
        "df_cudf_test_Rap = df_cudf_Rap.head(n=500)\n",
        "df_cudf_train_Rap = df_cudf_Rap.tail(n=1998)\n",
        "\n",
        "df_cudf_test_No_Rap = df_cudf_No_Rap.head(n=2500)\n",
        "df_cudf_train_No_Rap = df_cudf_No_Rap.tail(n=9398)"
      ],
      "metadata": {
        "id": "AzS6n1pUXQcp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression Models"
      ],
      "metadata": {
        "id": "-N42w5Bts-JH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the input features and target variable\n",
        "X = df_cudf_train[[\"danceability\", \"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"valence\",\"tempo\",\"minutes\",\"word_count\",\"words_per_minute\",\"repetition_pct\",\"stopword_pct\",\"profanity_pct\",\"negative_pct\",\"positive_pct\",\"Sentiment\",\"instrumentalnessFlag\",\"livenessFlag\",\"acousticnessFlag\",\"SpeechinessVsWordCount\",\"instrumentalnessFlagVsrepetition_pct\",\"acousticnessFlagnessVsrepetition_pct\",\"acousticnessFlagnessVsloudness\"]]\n",
        "y = df_cudf_train['track_popularity']\n",
        "\n",
        "# create the linear regression model\n",
        "linreg = LinearRegression()\n",
        "\n",
        "# define the grid of hyperparameters just so I can perform regular k-fold cv using Gridsearch to keep same writing\n",
        "parameters = {'fit_intercept': [True], 'normalize': [True]}\n",
        "\n",
        "# perform grid search with cross-validation to find the best hyperparameters\n",
        "grid_search = GridSearchCV(linreg, parameters, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X.to_cupy().get(), y.to_cupy().get())\n",
        "\n",
        "# extract the best model and make predictions on new data\n",
        "best_model = grid_search.best_estimator_\n",
        "X_test = df_cudf_test[[\"danceability\", \"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"valence\",\"tempo\",\"minutes\",\"word_count\",\"words_per_minute\",\"repetition_pct\",\"stopword_pct\",\"profanity_pct\",\"negative_pct\",\"positive_pct\",\"Sentiment\",\"instrumentalnessFlag\",\"livenessFlag\",\"acousticnessFlag\",\"SpeechinessVsWordCount\",\"instrumentalnessFlagVsrepetition_pct\",\"acousticnessFlagnessVsrepetition_pct\",\"acousticnessFlagnessVsloudness\"]]\n",
        "y_test = df_cudf_test['track_popularity']\n",
        "y_pred = best_model.predict(X_test.to_cupy().get())\n",
        "\n",
        "# calculate the root mean squared error of the predictions\n",
        "rmse = mean_squared_error(y_test.to_cupy().get(), y_pred, squared=False)\n",
        "mae = mean_absolute_error(y_test.to_cupy().get(), y_pred)\n",
        "\n",
        "# print the root mean squared error\n",
        "print(f\"Root mean squared error: {rmse:.4f}\")\n",
        "print(\"Mean Abosolute Error:\", mae)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a79HgtNqg6R5",
        "outputId": "6215b399-65c5-43ee-d4e9-1afb071e4d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root mean squared error: 23.6168\n",
            "Mean Abosolute Error: 19.747772904597976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the input features and target variable\n",
        "X = df_cudf_train[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y = df_cudf_train['track_popularity']\n",
        "\n",
        "# create the linear regression model\n",
        "linreg = LinearRegression()\n",
        "\n",
        "# define the grid of hyperparameters just so I can perform regular k-fold cv using Gridsearch to keep same writing\n",
        "parameters = {'fit_intercept': [True], 'normalize': [True]}\n",
        "\n",
        "# perform grid search with cross-validation to find the best hyperparameters\n",
        "grid_search = GridSearchCV(linreg, parameters, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X.to_cupy().get(), y.to_cupy().get())\n",
        "\n",
        "# extract the best model and make predictions on new data\n",
        "best_model = grid_search.best_estimator_\n",
        "X_test = df_cudf_test[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y_test = df_cudf_test['track_popularity']\n",
        "y_pred = best_model.predict(X_test.to_cupy().get())\n",
        "\n",
        "# calculate the root mean squared error of the predictions\n",
        "rmse = mean_squared_error(y_test.to_cupy().get(), y_pred, squared=False)\n",
        "mae = mean_absolute_error(y_test.to_cupy().get(), y_pred)\n",
        "\n",
        "# print the root mean squared error\n",
        "print(f\"Root mean squared error: {rmse:.4f}\")\n",
        "print(\"Mean Abosolute Error:\", mae)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QDVbH1tEnJ1",
        "outputId": "9a936325-4187-4f8e-bf42-69e2d1b5595a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root mean squared error: 23.6102\n",
            "Mean Abosolute Error: 19.731994804441857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the input features and target variable\n",
        "X = df_cudf_train_No_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y = df_cudf_train_No_Rap['track_popularity']\n",
        "\n",
        "# create the linear regression model\n",
        "linreg = LinearRegression()\n",
        "\n",
        "# define the grid of hyperparameters just so I can perform regular k-fold cv using Gridsearch to keep same writing\n",
        "parameters = {'fit_intercept': [True], 'normalize': [True]}\n",
        "\n",
        "# perform grid search with cross-validation to find the best hyperparameters\n",
        "grid_search = GridSearchCV(linreg, parameters, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X.to_cupy().get(), y.to_cupy().get())\n",
        "\n",
        "# extract the best model and make predictions on new data\n",
        "best_model = grid_search.best_estimator_\n",
        "X_test = df_cudf_test_No_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y_test = df_cudf_test_No_Rap['track_popularity']\n",
        "y_pred = best_model.predict(X_test.to_cupy().get())\n",
        "\n",
        "# calculate the root mean squared error of the predictions\n",
        "rmse = mean_squared_error(y_test.to_cupy().get(), y_pred, squared=False)\n",
        "mae = mean_absolute_error(y_test.to_cupy().get(), y_pred)\n",
        "\n",
        "# print the root mean squared error\n",
        "print(f\"Root mean squared error: {rmse:.4f}\")\n",
        "print(\"Mean Abosolute Error:\", mae)\n"
      ],
      "metadata": {
        "id": "zLaWeIi2D8IB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3af1a0a0-40da-4234-bf60-3393eed59554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root mean squared error: 23.3707\n",
            "Mean Abosolute Error: 19.617312250627933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the input features and target variable\n",
        "X = df_cudf_train_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y = df_cudf_train_Rap['track_popularity']\n",
        "\n",
        "# create the linear regression model\n",
        "linreg = LinearRegression()\n",
        "\n",
        "# define the grid of hyperparameters just so I can perform regular k-fold cv using Gridsearch to keep same writing\n",
        "parameters = {'fit_intercept': [True], 'normalize': [True]}\n",
        "\n",
        "# perform grid search with cross-validation to find the best hyperparameters\n",
        "grid_search = GridSearchCV(linreg, parameters, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X.to_cupy().get(), y.to_cupy().get())\n",
        "\n",
        "# extract the best model and make predictions on new data\n",
        "best_model = grid_search.best_estimator_\n",
        "X_test = df_cudf_test_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y_test = df_cudf_test_Rap['track_popularity']\n",
        "y_pred = best_model.predict(X_test.to_cupy().get())\n",
        "\n",
        "# calculate the root mean squared error of the predictions\n",
        "rmse = mean_squared_error(y_test.to_cupy().get(), y_pred, squared=False)\n",
        "mae = mean_absolute_error(y_test.to_cupy().get(), y_pred)\n",
        "\n",
        "# print the root mean squared error\n",
        "print(f\"Root mean squared error: {rmse:.4f}\")\n",
        "print(\"Mean Abosolute Error:\", mae)\n"
      ],
      "metadata": {
        "id": "3aslicv-vWDp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c59abda6-a9cd-4475-ed64-51d7e7c790e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root mean squared error: 24.8378\n",
            "Mean Abosolute Error: 20.350762491122445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ridge Regression Models"
      ],
      "metadata": {
        "id": "3sY6q1gRr6oV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the input features and target variable\n",
        "X = df_cudf_train[[\"danceability\", \"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"valence\",\"tempo\",\"minutes\",\"word_count\",\"words_per_minute\",\"repetition_pct\",\"stopword_pct\",\"profanity_pct\",\"negative_pct\",\"positive_pct\",\"Sentiment\",\"instrumentalnessFlag\",\"livenessFlag\",\"acousticnessFlag\",\"SpeechinessVsWordCount\",\"instrumentalnessFlagVsrepetition_pct\",\"acousticnessFlagnessVsrepetition_pct\",\"acousticnessFlagnessVsloudness\"]]\n",
        "y = df_cudf_train['track_popularity']\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_test = df_cudf_test[[\"danceability\", \"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"valence\",\"tempo\",\"minutes\",\"word_count\",\"words_per_minute\",\"repetition_pct\",\"stopword_pct\",\"profanity_pct\",\"negative_pct\",\"positive_pct\",\"Sentiment\",\"instrumentalnessFlag\",\"livenessFlag\",\"acousticnessFlag\",\"SpeechinessVsWordCount\",\"instrumentalnessFlagVsrepetition_pct\",\"acousticnessFlagnessVsrepetition_pct\",\"acousticnessFlagnessVsloudness\"]]\n",
        "y_test = df_cudf_test['track_popularity']\n",
        "\n",
        "# create a Ridge regression estimator\n",
        "alpha_range = [0.001, 0.01, 0.1, 1.0]\n",
        "ridge = Ridge(fit_intercept=True, normalize=False, solver='eig')\n",
        "\n",
        "# perform a grid search to find the best alpha value\n",
        "grid_search = GridSearchCV(ridge, {'alpha': alpha_range}, cv=5, refit = True)\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# print the best alpha value and corresponding score\n",
        "print('Best alpha:', grid_search.best_params_['alpha'])\n",
        "\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# calculate the root mean squared error of the predictions\n",
        "rmse = mean_squared_error(y_test.to_cupy().get(), y_pred, squared=False)\n",
        "mae = mean_absolute_error(y_test.to_cupy().get(), y_pred)\n",
        "\n",
        "# print the root mean squared error\n",
        "print(f\"Root mean squared error: {rmse:.4f}\")\n",
        "print(\"Mean Abosolute Error:\", mae)\n",
        "\n"
      ],
      "metadata": {
        "id": "qrsuyb7sTN4q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dba3da1f-d359-42e8-a5d4-69a4777267ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best alpha: 1.0\n",
            "Root mean squared error: 23.6092\n",
            "Mean Abosolute Error: 19.742151753731786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the input features and target variable\n",
        "X = df_cudf_train[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y = df_cudf_train['track_popularity']\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_test = df_cudf_test[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y_test = df_cudf_test['track_popularity']\n",
        "\n",
        "# create a Ridge regression estimator\n",
        "alpha_range = [0.001, 0.01, 0.1, 1.0]\n",
        "ridge = Ridge(fit_intercept=True, normalize=False, solver='eig')\n",
        "\n",
        "# perform a grid search to find the best alpha value\n",
        "grid_search = GridSearchCV(ridge, {'alpha': alpha_range}, cv=5, refit = True)\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# print the best alpha value and corresponding score\n",
        "print('Best alpha:', grid_search.best_params_['alpha'])\n",
        "\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# calculate the accuracy of the predictions\n",
        "accuracy = mean_squared_error(y_test, y_pred)**0.5\n",
        "\n",
        "# print the accuracy and confusion matrix\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD5g6qub9vhb",
        "outputId": "e7b86139-2e6d-4c35-afb1-c00d30c73d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best alpha: 0.1\n",
            "Accuracy: 23.6098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the input features and target variable\n",
        "X = df_cudf_train_No_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y = df_cudf_train_No_Rap['track_popularity']\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_test = df_cudf_test_No_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y_test = df_cudf_test_No_Rap['track_popularity']\n",
        "\n",
        "# create a Ridge regression estimator\n",
        "alpha_range = [0.001, 0.01, 0.1, 1.0]\n",
        "ridge = Ridge(fit_intercept=True, normalize=False, solver='eig')\n",
        "\n",
        "# perform a grid search to find the best alpha value\n",
        "grid_search = GridSearchCV(ridge, {'alpha': alpha_range}, cv=5, refit = True)\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# print the best alpha value and corresponding score\n",
        "print('Best alpha:', grid_search.best_params_['alpha'])\n",
        "\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# calculate the accuracy of the predictions\n",
        "accuracy = mean_squared_error(y_test, y_pred)**0.5\n",
        "\n",
        "# print the accuracy and confusion matrix\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "NGCmFIZLscwd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24ab9f11-1c11-4846-9238-2817efaa3102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best alpha: 0.1\n",
            "Accuracy: 23.3703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the input features and target variable\n",
        "X = df_cudf_train_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y = df_cudf_train_Rap['track_popularity']\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_test = df_cudf_test_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y_test = df_cudf_test_Rap['track_popularity']\n",
        "\n",
        "# create a Ridge regression estimator\n",
        "alpha_range = [0.001, 0.01, 0.1, 1.0]\n",
        "ridge = Ridge(fit_intercept=True, normalize=False, solver='eig')\n",
        "\n",
        "# perform a grid search to find the best alpha value\n",
        "grid_search = GridSearchCV(ridge, {'alpha': alpha_range}, cv=5, refit = True)\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# print the best alpha value and corresponding score\n",
        "print('Best alpha:', grid_search.best_params_['alpha'])\n",
        "\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# calculate the accuracy of the predictions\n",
        "accuracy = mean_squared_error(y_test, y_pred)**0.5\n",
        "\n",
        "# print the accuracy and confusion matrix\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "jC4xJlBxsc5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81ce0137-1eb0-4998-8e0f-bc0fb136b7b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best alpha: 0.1\n",
            "Accuracy: 24.8262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lasso Models"
      ],
      "metadata": {
        "id": "UWonegz7r97C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the input features and target variable\n",
        "X = df_cudf_train[[\"danceability\", \"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"valence\",\"tempo\",\"minutes\",\"word_count\",\"words_per_minute\",\"repetition_pct\",\"stopword_pct\",\"profanity_pct\",\"negative_pct\",\"positive_pct\",\"Sentiment\",\"instrumentalnessFlag\",\"livenessFlag\",\"acousticnessFlag\",\"SpeechinessVsWordCount\",\"instrumentalnessFlagVsrepetition_pct\",\"acousticnessFlagnessVsrepetition_pct\",\"acousticnessFlagnessVsloudness\"]]\n",
        "y = df_cudf_train['track_popularity']\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_test = df_cudf_test[[\"danceability\", \"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"valence\",\"tempo\",\"minutes\",\"word_count\",\"words_per_minute\",\"repetition_pct\",\"stopword_pct\",\"profanity_pct\",\"negative_pct\",\"positive_pct\",\"Sentiment\",\"instrumentalnessFlag\",\"livenessFlag\",\"acousticnessFlag\",\"SpeechinessVsWordCount\",\"instrumentalnessFlagVsrepetition_pct\",\"acousticnessFlagnessVsrepetition_pct\",\"acousticnessFlagnessVsloudness\"]]\n",
        "y_test = df_cudf_test['track_popularity']\n",
        "\n",
        "# create a Ridge regression estimator\n",
        "alpha_range = [0.001, 0.01, 0.1, 1.0]\n",
        "lasso = Lasso()\n",
        "\n",
        "# perform a grid search to find the best alpha value\n",
        "grid_search = GridSearchCV(lasso, {'alpha': alpha_range}, cv=5, refit = True)\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# print the best alpha value and corresponding score\n",
        "print('Best alpha:', grid_search.best_params_['alpha'])\n",
        "\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# calculate the root mean squared error of the predictions\n",
        "rmse = mean_squared_error(y_test.to_cupy().get(), y_pred, squared=False)\n",
        "mae = mean_absolute_error(y_test.to_cupy().get(), y_pred)\n",
        "\n",
        "# print the root mean squared error\n",
        "print(f\"Root mean squared error: {rmse:.4f}\")\n",
        "print(\"Mean Abosolute Error:\", mae)\n"
      ],
      "metadata": {
        "id": "5W8WcC7nDtcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8dc5775-f321-49eb-83d6-095c0eabd243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best alpha: 0.001\n",
            "Root mean squared error: 23.6162\n",
            "Mean Abosolute Error: 19.738793983239095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the input features and target variable\n",
        "X = df_cudf_train[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y = df_cudf_train['track_popularity']\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_test = df_cudf_test[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y_test = df_cudf_test['track_popularity']\n",
        "\n",
        "# create a Ridge regression estimator\n",
        "alpha_range = [0.001, 0.01, 0.1, 1.0]\n",
        "lasso = Lasso()\n",
        "\n",
        "# perform a grid search to find the best alpha value\n",
        "grid_search = GridSearchCV(lasso, {'alpha': alpha_range}, cv=5, refit = True)\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# print the best alpha value and corresponding score\n",
        "print('Best alpha:', grid_search.best_params_['alpha'])\n",
        "\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# calculate the accuracy of the predictions\n",
        "accuracy = mean_squared_error(y_test, y_pred)**0.5\n",
        "\n",
        "# print the accuracy and confusion matrix\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogyW3yZfDSwm",
        "outputId": "ea5608ef-35c0-42f5-a964-278b635c1038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best alpha: 0.001\n",
            "Accuracy: 23.6173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the input features and target variable\n",
        "X = df_cudf_train_No_Rap[[\"energy\", \"loudness\", \"speechiness\", \"SpeechinessVsWordCount\", \"tempo\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y = df_cudf_train_No_Rap['track_popularity']\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_test = df_cudf_test_No_Rap[[\"energy\", \"loudness\", \"speechiness\", \"SpeechinessVsWordCount\", \"tempo\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y_test = df_cudf_test_No_Rap['track_popularity']\n",
        "\n",
        "# create a Ridge regression estimator\n",
        "alpha_range = [0.001, 0.01, 0.1, 1.0]\n",
        "lasso = Lasso()\n",
        "\n",
        "# perform a grid search to find the best alpha value\n",
        "grid_search = GridSearchCV(lasso, {'alpha': alpha_range}, cv=5, refit = True)\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# print the best alpha value and corresponding score\n",
        "print('Best alpha:', grid_search.best_params_['alpha'])\n",
        "\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# calculate the accuracy of the predictions\n",
        "accuracy = mean_squared_error(y_test, y_pred)**0.5\n",
        "\n",
        "# print the accuracy and confusion matrix\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "9bjK0jWjuQK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c01f536-a8cb-417b-fe59-3e2dd01fd9be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best alpha: 0.001\n",
            "Accuracy: 23.3717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the input features and target variable\n",
        "X = df_cudf_train_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y = df_cudf_train_Rap['track_popularity']\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_test = df_cudf_test_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y_test = df_cudf_test_Rap['track_popularity']\n",
        "\n",
        "# create a Ridge regression estimator\n",
        "alpha_range = [0.001, 0.01, 0.1, 1.0]\n",
        "lasso = Lasso()\n",
        "\n",
        "# perform a grid search to find the best alpha value\n",
        "grid_search = GridSearchCV(lasso, {'alpha': alpha_range}, cv=5, refit = True)\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# print the best alpha value and corresponding score\n",
        "print('Best alpha:', grid_search.best_params_['alpha'])\n",
        "\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# calculate the accuracy of the predictions\n",
        "accuracy = mean_squared_error(y_test, y_pred)**0.5\n",
        "\n",
        "# print the accuracy and confusion matrix\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "RTRA1CLKuQQm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46fffda8-3b11-400b-ab05-2e2119ef48dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best alpha: 0.001\n",
            "Accuracy: 24.8357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression Models"
      ],
      "metadata": {
        "id": "cOHPSlEQryKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = cuml.LogisticRegression(multi_class='multinomial')\n",
        "\n",
        "# define the input features and target variable\n",
        "X = df_cudf_train[[\"danceability\", \"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"valence\",\"tempo\",\"minutes\",\"word_count\",\"words_per_minute\",\"repetition_pct\",\"stopword_pct\",\"profanity_pct\",\"negative_pct\",\"positive_pct\",\"Sentiment\",\"instrumentalnessFlag\",\"livenessFlag\",\"acousticnessFlag\",\"SpeechinessVsWordCount\",\"instrumentalnessFlagVsrepetition_pct\",\"acousticnessFlagnessVsrepetition_pct\",\"acousticnessFlagnessVsloudness\"]]\n",
        "y = df_cudf_train['HitOrMiss']\n",
        "\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make predictions on new data\n",
        "X_test = df_cudf_test[[\"danceability\", \"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"valence\",\"tempo\",\"minutes\",\"word_count\",\"words_per_minute\",\"repetition_pct\",\"stopword_pct\",\"profanity_pct\",\"negative_pct\",\"positive_pct\",\"Sentiment\",\"instrumentalnessFlag\",\"livenessFlag\",\"acousticnessFlag\",\"SpeechinessVsWordCount\",\"instrumentalnessFlagVsrepetition_pct\",\"acousticnessFlagnessVsrepetition_pct\",\"acousticnessFlagnessVsloudness\"]]\n",
        "y_test = df_cudf_test['HitOrMiss']\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# calculate the accuracy of the predictions\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# print the accuracy\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# calculate the f1 score of the model\n",
        "f1 = f1_score(y_test.to_cupy().get(), y_pred.to_cupy().get(), average=None)\n",
        "print(f\"F1 scores for each class: {f1}\")\n"
      ],
      "metadata": {
        "id": "A0SFQwSm4E5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94d8c849-7c65-432c-d890-eb600665be23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I] [00:06:28.663364] Unused keyword parameter: multi_class during cuML estimator initialization\n",
            "[W] [00:06:31.434540] L-BFGS: max iterations reached\n",
            "[W] [00:06:31.435720] Maximum iterations reached before solver is converged. To increase model accuracy you can increase the number of iterations (max_iter) or improve the scaling of the input data.\n",
            "Accuracy: 0.7377\n",
            "F1 scores for each class: [0.         0.84855491 0.24719101]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = cuml.LogisticRegression(multi_class='multinomial')\n",
        "\n",
        "# define the input features and target variable\n",
        "X = df_cudf_train[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y = df_cudf_train['HitOrMiss']\n",
        "\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make predictions on new data\n",
        "X_test = df_cudf_test[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y_test = df_cudf_test['HitOrMiss']\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# calculate the accuracy of the predictions\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# print the accuracy\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# calculate the f1 score of the model\n",
        "f1 = f1_score(y_test.to_cupy().get(), y_pred.to_cupy().get(), average=None)\n",
        "print(f\"F1 scores for each class: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6jOrIGkio-K",
        "outputId": "bdd06077-879a-4078-ecb3-726193f1134a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I] [00:06:31.460267] Unused keyword parameter: multi_class during cuML estimator initialization\n",
            "[W] [00:06:32.115132] L-BFGS: max iterations reached\n",
            "[W] [00:06:32.116566] Maximum iterations reached before solver is converged. To increase model accuracy you can increase the number of iterations (max_iter) or improve the scaling of the input data.\n",
            "Accuracy: 0.7377\n",
            "F1 scores for each class: [0.         0.84856648 0.19512195]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = cuml.LogisticRegression(multi_class='multinomial')\n",
        "\n",
        "# define the input features and target variable\n",
        "X = df_cudf_train_No_Rap[[\"energy\", \"loudness\", \"speechiness\", \"SpeechinessVsWordCount\", \"tempo\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y = df_cudf_train_No_Rap['HitOrMiss']\n",
        "\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make predictions on new data\n",
        "X_test = df_cudf_test_No_Rap[[\"energy\", \"loudness\", \"speechiness\", \"SpeechinessVsWordCount\", \"tempo\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y_test = df_cudf_test_No_Rap['HitOrMiss']\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# calculate the accuracy of the predictions\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# print the accuracy\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# calculate the f1 score of the model\n",
        "f1 = f1_score(y_test.to_cupy().get(), y_pred.to_cupy().get(), average=None)\n",
        "print(f\"F1 scores for each class: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_93v3s0jp5H",
        "outputId": "bf919a2f-f8f8-48e2-ae02-6f8801b1fdce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I] [00:06:32.134415] Unused keyword parameter: multi_class during cuML estimator initialization\n",
            "[W] [00:06:32.748591] L-BFGS: max iterations reached\n",
            "[W] [00:06:32.749809] Maximum iterations reached before solver is converged. To increase model accuracy you can increase the number of iterations (max_iter) or improve the scaling of the input data.\n",
            "Accuracy: 0.7460\n",
            "F1 scores for each class: [0.         0.85405654 0.21538462]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = cuml.LogisticRegression(multi_class='multinomial')\n",
        "\n",
        "# define the input features and target variable\n",
        "X = df_cudf_train_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y = df_cudf_train_Rap['HitOrMiss']\n",
        "\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make predictions on new data\n",
        "X_test = df_cudf_test_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y_test = df_cudf_test_Rap['HitOrMiss']\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# calculate the accuracy of the predictions\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# print the accuracy\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# calculate the f1 score of the model\n",
        "f1 = f1_score(y_test.to_cupy().get(), y_pred.to_cupy().get(), average=None)\n",
        "print(f\"F1 scores for each class: {f1}\")\n"
      ],
      "metadata": {
        "id": "-kqCUG_SugFF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c3924be-2f66-41d5-dd2b-d3ac2a8a8627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I] [00:06:32.771185] Unused keyword parameter: multi_class during cuML estimator initialization\n",
            "Accuracy: 0.6900\n",
            "F1 scores for each class: [0.         0.81666667 0.18181818]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Models"
      ],
      "metadata": {
        "id": "44t0-M0msAUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the input features and target variable\n",
        "X = df_cudf_train[[\"danceability\", \"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"valence\",\"tempo\",\"minutes\",\"word_count\",\"words_per_minute\",\"repetition_pct\",\"stopword_pct\",\"profanity_pct\",\"negative_pct\",\"positive_pct\",\"Sentiment\",\"instrumentalnessFlag\",\"livenessFlag\",\"acousticnessFlag\",\"SpeechinessVsWordCount\",\"instrumentalnessFlagVsrepetition_pct\",\"acousticnessFlagnessVsrepetition_pct\",\"acousticnessFlagnessVsloudness\"]]\n",
        "y = df_cudf_train['HitOrMiss']\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_test = df_cudf_test[[\"danceability\", \"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"valence\",\"tempo\",\"minutes\",\"word_count\",\"words_per_minute\",\"repetition_pct\",\"stopword_pct\",\"profanity_pct\",\"negative_pct\",\"positive_pct\",\"Sentiment\",\"instrumentalnessFlag\",\"livenessFlag\",\"acousticnessFlag\",\"SpeechinessVsWordCount\",\"instrumentalnessFlagVsrepetition_pct\",\"acousticnessFlagnessVsrepetition_pct\",\"acousticnessFlagnessVsloudness\"]]\n",
        "y_test = df_cudf_test['HitOrMiss']\n",
        "\n",
        "# define a range of hyperparameters to search over\n",
        "param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, 15]}\n",
        "\n",
        "# initialize a Random Forest classifier estimator\n",
        "rf = RandomForestClassifier(max_features='auto')\n",
        "\n",
        "# perform grid search over the hyperparameters\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X.to_cupy().get(), y.to_cupy().get())\n",
        "\n",
        "# print the best performing hyperparameters and their performance\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Average score:\", grid_search.best_score_)\n",
        "print(\"Standard deviation:\", grid_search.cv_results_['std_test_score'][grid_search.best_index_])\n",
        "\n",
        "# extract the best performing random forest\n",
        "best_rf = grid_search.best_estimator_\n",
        "\n",
        "# train the best performing random forest on the entire dataset\n",
        "best_rf.fit(X, y)\n",
        "\n",
        "# use the best performing random forest for prediction\n",
        "predictions = best_rf.predict(X_test)\n",
        "\n",
        "# calculate the accuracy of the predictions\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "# print the accuracy and confusion matrix\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# calculate the f1 score of the model\n",
        "f1 = f1_score(y_test.to_cupy().get(), predictions.to_cupy().get(), average=None)\n",
        "print(f\"F1 scores for each class: {f1}\")\n"
      ],
      "metadata": {
        "id": "6z5NDFAqvWIq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63e2491f-9a09-405f-8674-87f48ecdf32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n",
            "  ret = func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'max_depth': 10, 'n_estimators': 50}\n",
            "Average score: 0.7418393339645736\n",
            "Standard deviation: 0.001175853789597843\n",
            "Accuracy: 0.7380\n",
            "F1 scores for each class: [0.00825309 0.84898746 0.22727273]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the input features and target variable\n",
        "X = df_cudf_train[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y = df_cudf_train['HitOrMiss']\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_test = df_cudf_test[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y_test = df_cudf_test['HitOrMiss']\n",
        "\n",
        "# define a range of hyperparameters to search over\n",
        "param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, 15]}\n",
        "\n",
        "# initialize a Random Forest classifier estimator\n",
        "rf = RandomForestClassifier(max_features='auto')\n",
        "\n",
        "# perform grid search over the hyperparameters\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X.to_cupy().get(), y.to_cupy().get())\n",
        "\n",
        "# print the best performing hyperparameters and their performance\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Average score:\", grid_search.best_score_)\n",
        "print(\"Standard deviation:\", grid_search.cv_results_['std_test_score'][grid_search.best_index_])\n",
        "\n",
        "# extract the best performing random forest\n",
        "best_rf = grid_search.best_estimator_\n",
        "\n",
        "# train the best performing random forest on the entire dataset\n",
        "best_rf.fit(X, y)\n",
        "\n",
        "# use the best performing random forest for prediction\n",
        "predictions = best_rf.predict(X_test)\n",
        "\n",
        "# calculate the accuracy of the predictions\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "# print the accuracy and confusion matrix\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# calculate the f1 score of the model\n",
        "f1 = f1_score(y_test.to_cupy().get(), predictions.to_cupy().get(), average=None)\n",
        "print(f\"F1 scores for each class: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9rQBhbRAa4c",
        "outputId": "148dba1a-6b2a-413b-8933-127eb07215fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n",
            "  ret = func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'max_depth': 5, 'n_estimators': 200}\n",
            "Average score: 0.7414005450220549\n",
            "Standard deviation: 0.001216391937138455\n",
            "Accuracy: 0.7373\n",
            "F1 scores for each class: [0.         0.84840323 0.17283951]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the input features and target variable\n",
        "X = df_cudf_train_No_Rap[[\"energy\", \"loudness\", \"speechiness\", \"SpeechinessVsWordCount\", \"tempo\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y = df_cudf_train_No_Rap['HitOrMiss']\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_test = df_cudf_test_No_Rap[[\"energy\", \"loudness\", \"speechiness\", \"SpeechinessVsWordCount\", \"tempo\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y_test = df_cudf_test_No_Rap['HitOrMiss']\n",
        "\n",
        "# define a range of hyperparameters to search over\n",
        "param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, 15]}\n",
        "\n",
        "# initialize a Random Forest classifier estimator\n",
        "rf = RandomForestClassifier(max_features='auto')\n",
        "\n",
        "# perform grid search over the hyperparameters\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X.to_cupy().get(), y.to_cupy().get())\n",
        "\n",
        "# print the best performing hyperparameters and their performance\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Average score:\", grid_search.best_score_)\n",
        "print(\"Standard deviation:\", grid_search.cv_results_['std_test_score'][grid_search.best_index_])\n",
        "\n",
        "# extract the best performing random forest\n",
        "best_rf = grid_search.best_estimator_\n",
        "\n",
        "# train the best performing random forest on the entire dataset\n",
        "best_rf.fit(X, y)\n",
        "\n",
        "# use the best performing random forest for prediction\n",
        "predictions = best_rf.predict(X_test)\n",
        "\n",
        "# calculate the accuracy of the predictions\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "# print the accuracy and confusion matrix\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# calculate the f1 score of the model\n",
        "f1 = f1_score(y_test.to_cupy().get(), predictions.to_cupy().get(), average=None)\n",
        "print(f\"F1 scores for each class: {f1}\")\n"
      ],
      "metadata": {
        "id": "ja_o2JYybZ7o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b825c866-507e-4406-c51c-e5770c89f3a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n",
            "  ret = func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'max_depth': 10, 'n_estimators': 200}\n",
            "Average score: 0.739305991190425\n",
            "Standard deviation: 0.0019352570002557244\n",
            "Accuracy: 0.7464\n",
            "F1 scores for each class: [0.03311258 0.85364162 0.28169014]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the input features and target variable\n",
        "X = df_cudf_train_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y = df_cudf_train_Rap['HitOrMiss']\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_test = df_cudf_test_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"words_per_minute\", \"profanity_pct\"]]\n",
        "y_test = df_cudf_test_Rap['HitOrMiss']\n",
        "\n",
        "# define a range of hyperparameters to search over\n",
        "param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, 15]}\n",
        "\n",
        "# initialize a Random Forest classifier estimator\n",
        "rf = RandomForestClassifier(max_features='auto')\n",
        "\n",
        "# perform grid search over the hyperparameters\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X.to_cupy().get(), y.to_cupy().get())\n",
        "\n",
        "# print the best performing hyperparameters and their performance\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Average score:\", grid_search.best_score_)\n",
        "print(\"Standard deviation:\", grid_search.cv_results_['std_test_score'][grid_search.best_index_])\n",
        "\n",
        "# extract the best performing random forest\n",
        "best_rf = grid_search.best_estimator_\n",
        "\n",
        "# train the best performing random forest on the entire dataset\n",
        "best_rf.fit(X, y)\n",
        "\n",
        "# use the best performing random forest for prediction\n",
        "predictions = best_rf.predict(X_test)\n",
        "\n",
        "# calculate the accuracy of the predictions\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "# print the accuracy and confusion matrix\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# calculate the f1 score of the model\n",
        "f1 = f1_score(y_test.to_cupy().get(), predictions.to_cupy().get(), average=None)\n",
        "print(f\"F1 scores for each class: {f1}\")\n"
      ],
      "metadata": {
        "id": "GqB7vW_GYrag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb926089-9199-4f20-84a4-2b9508e43a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n",
            "  ret = func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'max_depth': 5, 'n_estimators': 200}\n",
            "Average score: 0.7537556390977443\n",
            "Standard deviation: 0.0023437322956368816\n",
            "Accuracy: 0.6880\n",
            "F1 scores for each class: [0.        0.8156956 0.0952381]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM Model"
      ],
      "metadata": {
        "id": "4BlZNxwusIrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the input features and target variable\n",
        "X = df_cudf_train[[\"danceability\", \"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"valence\",\"tempo\",\"minutes\",\"word_count\",\"words_per_minute\",\"repetition_pct\",\"stopword_pct\",\"profanity_pct\",\"negative_pct\",\"positive_pct\",\"Sentiment\",\"instrumentalnessFlag\",\"livenessFlag\",\"acousticnessFlag\",\"SpeechinessVsWordCount\",\"instrumentalnessFlagVsrepetition_pct\",\"acousticnessFlagnessVsrepetition_pct\",\"acousticnessFlagnessVsloudness\"]]\n",
        "y = df_cudf_train['HitOrMiss']\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_test = df_cudf_test[[\"danceability\", \"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"valence\",\"tempo\",\"minutes\",\"word_count\",\"words_per_minute\",\"repetition_pct\",\"stopword_pct\",\"profanity_pct\",\"negative_pct\",\"positive_pct\",\"Sentiment\", \"instrumentalnessFlag\",\"livenessFlag\",\"acousticnessFlag\",\"SpeechinessVsWordCount\",\"instrumentalnessFlagVsrepetition_pct\",\"acousticnessFlagnessVsrepetition_pct\",\"acousticnessFlagnessVsloudness\"]]\n",
        "y_test = df_cudf_test['HitOrMiss']\n",
        "\n",
        "# Create an SVC classifier object\n",
        "svc = LinearSVC(C=1.0)\n",
        "\n",
        "# Perform grid search cross-validation to find the best hyperparameters\n",
        "svc.fit(X.to_cupy().get(), y.to_cupy().get())\n",
        "\n",
        "# Make predictions on test data using the best model\n",
        "y_pred = svc.predict(X_test)\n",
        "\n",
        "# Calculate accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print('svc accuracy:', accuracy)\n",
        "\n",
        "# calculate the f1 score of the model\n",
        "f1 = f1_score(y_test.to_cupy().get(), y_pred.to_cupy().get(), average=None)\n",
        "print(f\"F1 scores for each class: {f1}\")"
      ],
      "metadata": {
        "id": "UcWjiATSfFJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b97f9f07-1341-47c0-abeb-4e852b5823b8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "svc accuracy: 0.7363333106040955\n",
            "F1 scores for each class: [0.         0.84791386 0.12307692]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gMq5Cu5Prr7U",
        "-N42w5Bts-JH",
        "3sY6q1gRr6oV",
        "UWonegz7r97C",
        "cOHPSlEQryKJ",
        "44t0-M0msAUB",
        "4BlZNxwusIrr"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
