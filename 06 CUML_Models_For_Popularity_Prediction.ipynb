{"cells":[{"cell_type":"markdown","source":["# Initial Setup"],"metadata":{"id":"RZ7GEuUIrlWg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UmyxGNv2ijMD"},"outputs":[],"source":["!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz\n","!tar xf spark-3.2.0-bin-hadoop3.2.tgz\n","!pip install -q findspark"]},{"cell_type":"code","source":["# Check GPU\n","!nvidia-smi"],"metadata":{"id":"T3T_HHcZL5Px","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682891616882,"user_tz":240,"elapsed":356,"user":{"displayName":"hi","userId":"15692922992261509059"}},"outputId":"c8de3cdd-d23e-4183-96f5-5f30d89570f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Apr 30 21:53:35 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    24W / 300W |      0MiB / 16384MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["# This get the RAPIDS-Colab install files and test check your GPU.  Run this and the next cell only.\n","# Please read the output of this cell.  If your Colab Instance is not RAPIDS compatible, it will warn you and give you remediation steps.\n","!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n","!python rapidsai-csp-utils/colab/pip-install.py"],"metadata":{"id":"kMm_tXE7Mcmm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682891616882,"user_tz":240,"elapsed":3,"user":{"displayName":"hi","userId":"15692922992261509059"}},"outputId":"cf8d2439-baaa-4950-80ff-d9c12fc26901"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'rapidsai-csp-utils' already exists and is not an empty directory.\n","Traceback (most recent call last):\n","  File \"/content/rapidsai-csp-utils/colab/pip-install.py\", line 28, in <module>\n","    if ('K80' not in gpu_name):\n","TypeError: a bytes-like object is required, not 'str'\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"38GsCdSRix-u"},"outputs":[],"source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"spark-3.2.0-bin-hadoop3.2\""]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","import findspark\n","findspark.init()\n","\n","import cudf, io, cuml\n","import cupy as cp\n","\n","from pyspark import SparkContext, SparkConf\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, pandas_udf, PandasUDFType\n","from pyspark.sql.types import StructType, StructField, DoubleType, LongType\n","\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"rapids\").getOrCreate()"],"metadata":{"id":"PlPD2DhsJwcf"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u8yU4NRQo015","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682891631431,"user_tz":240,"elapsed":1882,"user":{"displayName":"hi","userId":"15692922992261509059"}},"outputId":"8264d409-8a0a-446c-b372-0835d5f77cf0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Q1Eh4JS02ku"},"outputs":[],"source":["import json\n","\n","from pyspark.sql import Row\n","from pyspark.sql.types import *\n","from pyspark.sql.functions import explode, split, lower, regexp_replace, count, when, col\n","\n","from cuml.svm import SVC\n","from cuml.metrics import accuracy_score, mean_squared_error, confusion_matrix\n","from cuml.model_selection import GridSearchCV\n","from cuml.linear_model import Ridge, Lasso\n","from cuml.ensemble import RandomForestClassifier\n","\n","from sklearn.datasets import make_classification\n","\n","from sklearn.model_selection import cross_val_score\n","\n","from sklearn.metrics import f1_score"]},{"cell_type":"markdown","source":["# Data Preperation"],"metadata":{"id":"gMq5Cu5Prr7U"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"10VPirKh3suu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682891642228,"user_tz":240,"elapsed":10798,"user":{"displayName":"hi","userId":"15692922992261509059"}},"outputId":"6d84c275-e9c3-4d63-cdde-a5b09e551818"},"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+------------------------+--------------------+--------------------+--------------+--------------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+-----------+--------+-------+----+-------+----------+----------------+--------------+------------+-------------+------------+------------+---------+--------------------+\n","|            track_id|          track_name|        track_artist|track_popularity|      track_album_id|    track_album_name|track_album_release_date|       playlist_name|         playlist_id|playlist_genre|   playlist_subgenre|danceability|energy|key|loudness|mode|speechiness|acousticness|instrumentalness|liveness|valence|  tempo|duration_ms|language|genreID|year|minutes|word_count|words_per_minute|repetition_pct|stopword_pct|profanity_pct|negative_pct|positive_pct|Sentiment|   words_only_lyrics|\n","+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+------------------------+--------------------+--------------------+--------------+--------------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+-----------+--------+-------+----+-------+----------+----------------+--------------+------------+-------------+------------+------------+---------+--------------------+\n","|0EDQwboQDmswDRn58...|            Kingston|        Faye Webster|              59|4vt0V1SmkaK1Y440P...|Atlanta Millionai...|               5/24/2019|Ultimate Indie Pr...|37i9dQZF1DWTc5QDl...|           r&b|             hip pop|        0.73| 0.344| 10|  -9.541|   0|     0.0394|       0.138|         0.00128|   0.134|  0.543|142.129|     202160|      en|      2|2010|    3.4|       220|              64|          0.72|        0.42|          0.0|        0.01|        0.01|        2|The day that I me...|\n","|0HaAoQJ1PgF0gIm1o...|Where Them Niggaz...|         Pastor Troy|               9|5almm5i3TH8NFWo1M...|    Face Off Part II|                3/1/2005|    Southern Hip Hop|57sYMLFXGD4Zqizzc...|           rap|    southern hip hop|       0.809| 0.866|  6|  -5.221|   0|      0.254|     0.00672|               0|    0.12|  0.558|142.102|     213053|      en|      3|2000|    3.6|       380|             105|          0.55|        0.28|         0.08|        0.09|        0.01|        0|This that hard sh...|\n","|0i3utbege8Iy3q7Hy...|Klanga - De Hofna...|              Gostan|               5|4rcRFEkfAeLD4GMhe...|              Klanga|              11/28/2014|Chillout & Remixe...|4NlAd9NpIa92IjErM...|           pop|     indie poptimism|       0.719| 0.527|  6|  -9.077|   1|     0.0408|      0.0312|           0.716|   0.105|   0.58|123.955|     264293|      en|      1|2010|    4.4|       105|              23|          0.55|         0.3|         0.01|        0.01|        0.02|        2|Two thousand year...|\n","|0IXpUl1fn2QZcBavf...|Living After Midn...|        Judas Priest|              63|5bqtZRbUZUxUps8mr...|       British Steel|                    1980|Workday: Rock Cla...|37i9dQZF1DX1lwxXv...|          rock|        classic rock|        0.61| 0.824|  4|  -6.046|   1|     0.0534|      0.0136|        1.75E-06|  0.0606|  0.819|134.992|     210133|      en|      0|1980|    3.5|       340|              97|           0.8|        0.25|          0.0|        0.01|        0.04|        2|Living after midn...|\n","|0ooy3NjwsJreceWYC...|Never Let Me Down...|        Depeche Mode|              10|5Yyx661Ksxl2pmRUu...|Music for the Masses|               9/28/1987|Maxi Pop  GOLD (N...|2nRWtTI9a2LWjJ9Wy...|           pop|          electropop|       0.599| 0.719|  0|  -12.57|   1|     0.0288|       0.281|          0.0514|   0.693|  0.785| 106.08|     288000|      en|      1|1980|    4.8|       231|              48|          0.81|        0.38|          0.0|         0.0|        0.02|        2|Im taking a ride ...|\n","|0QyIxB3MqUoSQX0kB...|Sweet Emotion - S...|           Aerosmith|              39|3VNTh6evo3MyUsStA...|Aerosmith's Great...|              11/11/1980|       70s Hard Rock|6pZlZ20vt3aDjIKw9...|          rock|           hard rock|       0.473| 0.787|  2|  -9.898|   1|     0.0317|      0.0131|        8.76E-04|  0.0913|  0.603| 99.893|     192733|      en|      0|1980|    3.2|       162|              50|          0.51|        0.35|          0.0|        0.02|        0.02|        2|NA Sweet emotion ...|\n","|0tVv9FxhUjHrhF1DL...|         Fuji Opener|            Skrillex|              58|6xKK037rfCf2f6gf3...|         Show Tracks|               7/19/2019|          Nasty Bits|37i9dQZF1DX2VvACC...|           edm|       electro house|       0.662| 0.941|  1|  -1.641|   1|     0.0626|    3.75E-04|           0.029|   0.292|  0.579|149.982|     167200|      en|      4|2010|    2.8|        14|               5|          0.43|        0.29|          0.0|         0.0|        0.07|        2|Pop watch me pop ...|\n","|0yxWY5cPaPUpeAoqS...|         Tropic Love|            Diviners|              53|2iyxWjV2Rfe04h4uz...|         Tropic Love|               3/26/2015|          ElectroPop|0cuHKz65ZPqBX1brG...|           pop|          electropop|       0.746| 0.809|  2|  -6.429|   1|     0.0329|       0.236|        2.59E-05|   0.235|  0.493|104.989|     299440|      en|      1|2010|    5.0|       558|             111|          0.91|        0.37|          0.0|        0.02|        0.02|        1|I remember the oc...|\n","|15Trb1S2FDZSMLDzW...|            Promises|     The Cranberries|              56|2v9PjvIkQVnyQdtD1...|    Bury The Hatchet|               4/19/1999|The Cranberries B...|4E3K9oQgvLcKEz0wg...|          rock|          album rock|       0.501| 0.864|  4|  -3.231|   0|     0.0502|      0.0628|               0|   0.169|  0.247|130.063|     327573|      en|      0|1990|    5.5|       355|              64|          0.79|        0.44|          0.0|        0.04|        0.03|        0|Ooh ooh ooh ohh O...|\n","|1Ahp4PZ1vzdbzBCed...|             The One|         Jorja Smith|              62|3AlSuZnX4ZCab8eoW...|        Lost & Found|                6/8/2018|  urban CONTEMPORARY|1nFfDHtp8RY3obgen...|           r&b|  urban contemporary|       0.312| 0.661|  0|  -8.508|   0|      0.092|       0.252|        1.35E-04|   0.102|  0.443|  82.39|     197575|      en|      2|2010|    3.3|        69|              20|          0.45|        0.32|          0.0|        0.03|        0.04|        2|Never had to work...|\n","|1KgfeuVn5OlsBEtoE...|        Live Forever|               Oasis|              57|5zfhhKXHK0YQdvacC...|    Definitely Maybe|               8/29/1994|      Permanent Wave|5glAD13obyL0G9SH9...|          rock|      permanent wave|       0.335| 0.776|  9|   -5.32|   0|     0.0325|    9.27E-06|        9.51E-06|   0.369|  0.219|  90.59|     276867|      en|      0|1990|    4.6|       252|              54|          0.81|        0.27|          0.0|        0.02|         0.0|        0|Oh yeah Maybe I d...|\n","|1nHvUtf7NJBH1WzCh...|Calling Out - Ori...|                Dyro|               4|4IyK3VqdHW4KuKS1M...|         Calling Out|                5/5/2014|         Vocal House|5PCAWKfUWAUj8VeY8...|           edm|progressive elect...|       0.826| 0.861|  1|  -3.392|   0|       0.13|      0.0232|        4.28E-04|    0.12|   0.31|128.007|     271000|      en|      4|2010|    4.5|       128|              28|          0.84|        0.55|          0.0|        0.03|         0.0|        0|I find myself cal...|\n","|1pBO9JDqh1y3TbCKE...|           Nostalgic|       A R I Z O N A|              36|1mfUDy3N3YIHDlJp4...|           Nostalgic|               6/18/2019|           Dance Pop|37i9dQZF1DWZQaaqN...|           pop|           dance pop|       0.691| 0.538|  0|  -9.952|   1|      0.103|       0.246|           0.163|   0.178|  0.329| 99.972|     182668|      en|      1|2010|    3.0|       324|             108|          0.77|        0.25|          0.0|        0.02|        0.02|        1|Okay fine maybe I...|\n","|1xznGGDReH1oQq0xz...|           One Dance|               Drake|              20|3hARKC8cinq3mZLLA...|               Views|                5/6/2016|Electropop Hits  ...|7kyvBmlc1uSqsTL0E...|           pop|          electropop|       0.791| 0.619|  1|  -5.886|   1|     0.0532|     0.00784|         0.00423|   0.351|  0.371|103.989|     173987|      en|      1|2010|    2.9|      1182|             407|          0.93|        0.38|          0.0|        0.01|        0.02|        2|Baby I like your ...|\n","|2BgEsaKNfHUdlh97K...|                2002|          Anne-Marie|              83|7lPoGKpCGgdKFAxpu...|Speak Your Mind (...|               4/27/2018|Intro to Post-Tee...|6o6MNYZqHSkMAKcCH...|           pop|       post-teen pop|       0.697| 0.683|  1|  -2.881|   0|      0.117|      0.0372|               0|   0.137|  0.603| 96.133|     186987|      en|      1|2010|    3.1|        57|              18|           0.4|        0.39|          0.0|         0.0|        0.05|        2|I will always rem...|\n","|2C1HfPSxkTrp29qSc...| Motor City Madhouse|          Ted Nugent|              10|0n5v0O4M1D6Cw5d4K...|The Essential Ted...|              10/26/2010|       70s Hard Rock|6pZlZ20vt3aDjIKw9...|          rock|           hard rock|       0.527| 0.917|  7|  -7.368|   1|     0.0923|      0.0146|          0.0988|   0.135|  0.419|119.466|     273160|      en|      0|2010|    4.6|       194|              42|          0.68|        0.26|          0.0|        0.03|        0.03|        2|Woh welcome to my...|\n","|2CRz2pMU6A46P1cK3...|          I Dare You|                Jauz|              55|6qNKTCFnFxgM1SXl1...|          I Dare You|                6/7/2019|          Nasty Bits|37i9dQZF1DX2VvACC...|           edm|       electro house|       0.634| 0.953| 10|  -2.934|   0|     0.0633|       0.195|        8.08E-05|   0.115|  0.587|130.016|     296308|      en|      4|2010|    4.9|       416|              84|          0.97|         0.4|          0.0|        0.07|         0.0|        0|I dare you to mov...|\n","|2de98HzQLgj4mN9X6...|Wonderous Stories...|                 Yes|              38|2U4JHXMiBxsKH4dnY...|Going for the One...|                    1977|Progressive Rock ...|7GhTpb4eOp6403Bmg...|          rock|          album rock|       0.382| 0.605|  4|  -9.351|   1|     0.0292|       0.196|               0|  0.0994|  0.147|141.065|     229160|      en|      0|1970|    3.8|       198|              52|          0.64|        0.34|          0.0|        0.02|        0.05|        2|I awoke this morn...|\n","|2fY6tqgrlrg1ky9fg...|Wanted Dead Or Alive|            Bon Jovi|              14|5uU2uM1RGHfzlA12o...|   Slippery When Wet|                1/1/1986|  Classic Rock Drive|37i9dQZF1DXdOEFt9...|          rock|        classic rock|       0.257| 0.803|  7|  -3.886|   1|     0.0411|       0.137|          0.0156|   0.297|  0.294|150.818|     308667|      en|      0|1980|    5.1|       462|              90|          0.85|         0.3|          0.0|        0.05|         0.0|        0|Its all the same ...|\n","|2olVm1lHicpveMAo4...|   The Power Of Love|Huey Lewis & The ...|              72|0u34k1ANjgZ47uQfG...|Greatest Hits: Hu...|                1/1/2006|  Classic Rock Radio|4lIywN6kXl9KPm3OQ...|          rock|        classic rock|       0.768| 0.829|  5|  -5.109|   1|     0.0313|      0.0964|        2.92E-05|   0.097|  0.962|118.773|     234333|      en|      0|2000|    3.9|       294|              75|          0.69|        0.35|          0.0|        0.03|        0.09|        2|The power of love...|\n","+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+------------------------+--------------------+--------------------+--------------+--------------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+-----------+--------+-------+----+-------+----------+----------------+--------------+------------+-------------+------------+------------+---------+--------------------+\n","only showing top 20 rows\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["14398"]},"metadata":{},"execution_count":8}],"source":["#i have an extra folder named /H516 so my pathway might be different than yours\n","lyrics_df = spark.read.csv(\"/content/drive/My Drive/Colab Notebooks/spotify_with_word_counts.csv\", header=True)\n","\n","lyrics_df.show()\n","lyrics_df.count()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YkmYprg0AbH-"},"outputs":[],"source":["df_With_Extra_Columns = lyrics_df.withColumn(\"HitOrMiss\", \\\n","   when(lyrics_df.track_popularity < 21, 0). \\\n","   when(lyrics_df.track_popularity > 79, 2).\n","    otherwise(1) \\\n","  )\n","\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn(\"instrumentalnessFlag\", \\\n","   when(df_With_Extra_Columns.instrumentalness > .5, 1).\n","    otherwise(0) \\\n","  )\n","\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn(\"livenessFlag\", \\\n","   when(df_With_Extra_Columns.liveness > .5, 1).\n","    otherwise(0) \\\n","  )\n","\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn(\"acousticnessFlag\", \\\n","   when(df_With_Extra_Columns.acousticness > .5, 1).\n","    otherwise(0) \\\n","  )\n","\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn(\"SpeechinessVsWordCount\", \\\n","   df_With_Extra_Columns.speechiness * df_With_Extra_Columns.word_count\n","  )\n","\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn(\"instrumentalnessFlagVsrepetition_pct\", \\\n","   df_With_Extra_Columns.instrumentalnessFlag * df_With_Extra_Columns.repetition_pct\n","  )\n","\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn(\"acousticnessFlagnessVsrepetition_pct\", \\\n","   df_With_Extra_Columns.acousticnessFlag * df_With_Extra_Columns.repetition_pct\n","  )\n","\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn(\"acousticnessFlagnessVsloudness\", \\\n","   df_With_Extra_Columns.acousticnessFlag * df_With_Extra_Columns.loudness\n","  )\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pXLz5aZ8o-xL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682891646184,"user_tz":240,"elapsed":1901,"user":{"displayName":"hi","userId":"15692922992261509059"}},"outputId":"aafe928f-6402-4f71-a6ad-c03ef9fb5b35"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["14398"]},"metadata":{},"execution_count":10}],"source":["df_With_Extra_Columns.count()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ApJq40llhah5"},"outputs":[],"source":["df_With_Extra_Columns = df_With_Extra_Columns.withColumn('track_popularity', col('track_popularity').cast('int'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('genreID', col('genreID').cast('int'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('key', col('key').cast('int'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('mode', col('mode').cast('int'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('words_per_minute', col('words_per_minute').cast('int'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('word_count', col('word_count').cast('int'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('Sentiment', col('Sentiment').cast('int'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('danceability', col('danceability').cast('double'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('energy', col('energy').cast('double'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('loudness', col('loudness').cast('double'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('speechiness', col('speechiness').cast('double'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('acousticness', col('acousticness').cast('double'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('instrumentalness', col('instrumentalness').cast('double'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('liveness', col('liveness').cast('double'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('valence', col('valence').cast('double'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('tempo', col('tempo').cast('double'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('repetition_pct', col('repetition_pct').cast('double'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('stopword_pct', col('stopword_pct').cast('double'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('profanity_pct', col('profanity_pct').cast('double'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('minutes', col('minutes').cast('double'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('negative_pct', col('negative_pct').cast('double'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('positive_pct', col('positive_pct').cast('double'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('SpeechinessVsWordCount', col('SpeechinessVsWordCount').cast('double'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('instrumentalnessFlagVsrepetition_pct', col('instrumentalnessFlagVsrepetition_pct').cast('double'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('acousticnessFlagnessVsrepetition_pct', col('acousticnessFlagnessVsrepetition_pct').cast('double'))\n","df_With_Extra_Columns = df_With_Extra_Columns.withColumn('acousticnessFlagnessVsloudness', col('acousticnessFlagnessVsloudness').cast('double'))\n"]},{"cell_type":"code","source":["# Convert PySpark DataFrame to Pandas DataFrame\n","pdf_full = df_With_Extra_Columns.toPandas()\n","pdf_full.convert_dtypes().dtypes\n","\n","#randomize the pandas dataframe\n","pdf_full = pdf_full.sample(frac = 1)\n","\n","df_cudf_full = cudf.DataFrame.from_pandas(pdf_full)\n","df_cudf_full = df_cudf_full.dropna()\n","df_cudf_full.count()"],"metadata":{"id":"-ECl_n4QOl_W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682891656522,"user_tz":240,"elapsed":7451,"user":{"displayName":"hi","userId":"15692922992261509059"}},"outputId":"ae4f62fe-a641-4381-d254-f0e4eebac5d4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["track_id                                14396\n","track_name                              14396\n","track_artist                            14396\n","track_popularity                        14396\n","track_album_id                          14396\n","track_album_name                        14396\n","track_album_release_date                14396\n","playlist_name                           14396\n","playlist_id                             14396\n","playlist_genre                          14396\n","playlist_subgenre                       14396\n","danceability                            14396\n","energy                                  14396\n","key                                     14396\n","loudness                                14396\n","mode                                    14396\n","speechiness                             14396\n","acousticness                            14396\n","instrumentalness                        14396\n","liveness                                14396\n","valence                                 14396\n","tempo                                   14396\n","duration_ms                             14396\n","language                                14396\n","genreID                                 14396\n","year                                    14396\n","minutes                                 14396\n","word_count                              14396\n","words_per_minute                        14396\n","repetition_pct                          14396\n","stopword_pct                            14396\n","profanity_pct                           14396\n","negative_pct                            14396\n","positive_pct                            14396\n","Sentiment                               14396\n","words_only_lyrics                       14396\n","HitOrMiss                               14396\n","instrumentalnessFlag                    14396\n","livenessFlag                            14396\n","acousticnessFlag                        14396\n","SpeechinessVsWordCount                  14396\n","instrumentalnessFlagVsrepetition_pct    14396\n","acousticnessFlagnessVsrepetition_pct    14396\n","acousticnessFlagnessVsloudness          14396\n","dtype: int64"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["df_cudf_test = df_cudf_full.head(n=3000)\n","df_cudf_train = df_cudf_full.tail(n=11396)\n","\n","expression = \"(genreID != 3)\"\n","df_cudf_No_Rap = df_cudf_full.query(expression)\n","expression = \"(genreID == 3)\"\n","df_cudf_Rap = df_cudf_full.query(expression)\n","\n","df_cudf_test_Rap = df_cudf_Rap.head(n=500)\n","df_cudf_train_Rap = df_cudf_Rap.tail(n=1998)\n","\n","df_cudf_test_No_Rap = df_cudf_No_Rap.head(n=2500)\n","df_cudf_train_No_Rap = df_cudf_No_Rap.tail(n=9398)"],"metadata":{"id":"AzS6n1pUXQcp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Linear Regression Models"],"metadata":{"id":"-N42w5Bts-JH"}},{"cell_type":"code","source":["# define the input features and target variable\n","X = df_cudf_train[[\"danceability\", \"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"valence\",\"tempo\",\"minutes\",\"word_count\",\"words_per_minute\",\"repetition_pct\",\"stopword_pct\",\"profanity_pct\",\"negative_pct\",\"positive_pct\",\"Sentiment\",\"instrumentalnessFlag\",\"livenessFlag\",\"acousticnessFlag\",\"SpeechinessVsWordCount\",\"instrumentalnessFlagVsrepetition_pct\",\"acousticnessFlagnessVsrepetition_pct\",\"acousticnessFlagnessVsloudness\"]]\n","y = df_cudf_train['track_popularity']\n","\n","# create the linear regression model\n","linreg = LinearRegression()\n","\n","# define the grid of hyperparameters just so I can perform regular k-fold cv using Gridsearch to keep same writing\n","parameters = {'fit_intercept': [True], 'normalize': [True]}\n","\n","# perform grid search with cross-validation to find the best hyperparameters\n","grid_search = GridSearchCV(linreg, parameters, cv=5, scoring='neg_mean_squared_error')\n","grid_search.fit(X.to_cupy().get(), y.to_cupy().get())\n","\n","# extract the best model and make predictions on new data\n","best_model = grid_search.best_estimator_\n","X_test = df_cudf_test[[\"danceability\", \"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"valence\",\"tempo\",\"minutes\",\"word_count\",\"words_per_minute\",\"repetition_pct\",\"stopword_pct\",\"profanity_pct\",\"negative_pct\",\"positive_pct\",\"Sentiment\",\"instrumentalnessFlag\",\"livenessFlag\",\"acousticnessFlag\",\"SpeechinessVsWordCount\",\"instrumentalnessFlagVsrepetition_pct\",\"acousticnessFlagnessVsrepetition_pct\",\"acousticnessFlagnessVsloudness\"]]\n","y_test = df_cudf_test['track_popularity']\n","y_pred = best_model.predict(X_test.to_cupy().get())\n","\n","# calculate the root mean squared error of the predictions\n","rmse = mean_squared_error(y_test.to_cupy().get(), y_pred, squared=False)\n","mae = mean_absolute_error(y_test.to_cupy().get(), y_pred)\n","\n","# print the root mean squared error\n","print(f\"Root mean squared error: {rmse:.4f}\")\n","print(\"Mean Abosolute Error:\", mae)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a79HgtNqg6R5","executionInfo":{"status":"ok","timestamp":1682294136202,"user_tz":240,"elapsed":503,"user":{"displayName":"hi","userId":"15692922992261509059"}},"outputId":"386b436a-d93a-4626-f2e0-256f7c25cec9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[I] [23:55:34.966568] Unused keyword parameter: multi_class during cuML estimator initialization\n","[W] [23:55:35.550470] L-BFGS: max iterations reached\n","[W] [23:55:35.552196] Maximum iterations reached before solver is converged. To increase model accuracy you can increase the number of iterations (max_iter) or improve the scaling of the input data.\n","Accuracy: 0.7328\n"]}]},{"cell_type":"code","source":["# define the input features and target variable\n","X = df_cudf_train[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n","y = df_cudf_train['track_popularity']\n","\n","# create the linear regression model\n","linreg = LinearRegression()\n","\n","# define the grid of hyperparameters just so I can perform regular k-fold cv using Gridsearch to keep same writing\n","parameters = {'fit_intercept': [True], 'normalize': [True]}\n","\n","# perform grid search with cross-validation to find the best hyperparameters\n","grid_search = GridSearchCV(linreg, parameters, cv=5, scoring='neg_mean_squared_error')\n","grid_search.fit(X.to_cupy().get(), y.to_cupy().get())\n","\n","# extract the best model and make predictions on new data\n","best_model = grid_search.best_estimator_\n","X_test = df_cudf_test[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n","y_test = df_cudf_test['track_popularity']\n","y_pred = best_model.predict(X_test.to_cupy().get())\n","\n","# calculate the root mean squared error of the predictions\n","rmse = mean_squared_error(y_test.to_cupy().get(), y_pred, squared=False)\n","mae = mean_absolute_error(y_test.to_cupy().get(), y_pred)\n","\n","# print the root mean squared error\n","print(f\"Root mean squared error: {rmse:.4f}\")\n","print(\"Mean Abosolute Error:\", mae)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8QDVbH1tEnJ1","executionInfo":{"status":"ok","timestamp":1682895743140,"user_tz":240,"elapsed":262,"user":{"displayName":"hi","userId":"15692922992261509059"}},"outputId":"d6c276d4-3e69-4a7d-8a24-6dab7a1ce120"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Root mean squared error: 23.6190\n","Mean Abosolute Error: 19.90127658236349\n"]}]},{"cell_type":"code","source":["# define the input features and target variable\n","X = df_cudf_train_No_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n","y = df_cudf_train_No_Rap['track_popularity']\n","\n","# create the linear regression model\n","linreg = LinearRegression()\n","\n","# define the grid of hyperparameters just so I can perform regular k-fold cv using Gridsearch to keep same writing\n","parameters = {'fit_intercept': [True], 'normalize': [True]}\n","\n","# perform grid search with cross-validation to find the best hyperparameters\n","grid_search = GridSearchCV(linreg, parameters, cv=5, scoring='neg_mean_squared_error')\n","grid_search.fit(X.to_cupy().get(), y.to_cupy().get())\n","\n","# extract the best model and make predictions on new data\n","best_model = grid_search.best_estimator_\n","X_test = df_cudf_test_No_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n","y_test = df_cudf_test_No_Rap['track_popularity']\n","y_pred = best_model.predict(X_test.to_cupy().get())\n","\n","# calculate the root mean squared error of the predictions\n","rmse = mean_squared_error(y_test.to_cupy().get(), y_pred, squared=False)\n","mae = mean_absolute_error(y_test.to_cupy().get(), y_pred)\n","\n","# print the root mean squared error\n","print(f\"Root mean squared error: {rmse:.4f}\")\n","print(\"Mean Abosolute Error:\", mae)\n"],"metadata":{"id":"zLaWeIi2D8IB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682882484195,"user_tz":240,"elapsed":230,"user":{"displayName":"hi","userId":"15692922992261509059"}},"outputId":"7b3b20a5-a6f4-45a7-e34b-02ea50fa10ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cross-validation scores: [-568.07761605 -555.86636109 -553.44682266 -561.09289397 -567.49471964]\n","Mean test RMSE: 23.689569069151794\n"]}]},{"cell_type":"code","source":["# define the input features and target variable\n","X = df_cudf_train_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"words_per_minute\", \"profanity_pct\"]]\n","y = df_cudf_train_Rap['track_popularity']\n","\n","# create the linear regression model\n","linreg = LinearRegression()\n","\n","# define the grid of hyperparameters just so I can perform regular k-fold cv using Gridsearch to keep same writing\n","parameters = {'fit_intercept': [True], 'normalize': [True]}\n","\n","# perform grid search with cross-validation to find the best hyperparameters\n","grid_search = GridSearchCV(linreg, parameters, cv=5, scoring='neg_mean_squared_error')\n","grid_search.fit(X.to_cupy().get(), y.to_cupy().get())\n","\n","# extract the best model and make predictions on new data\n","best_model = grid_search.best_estimator_\n","X_test = df_cudf_test_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"words_per_minute\", \"profanity_pct\"]]\n","y_test = df_cudf_test_Rap['track_popularity']\n","y_pred = best_model.predict(X_test.to_cupy().get())\n","\n","# calculate the root mean squared error of the predictions\n","rmse = mean_squared_error(y_test.to_cupy().get(), y_pred, squared=False)\n","mae = mean_absolute_error(y_test.to_cupy().get(), y_pred)\n","\n","# print the root mean squared error\n","print(f\"Root mean squared error: {rmse:.4f}\")\n","print(\"Mean Abosolute Error:\", mae)\n"],"metadata":{"id":"3aslicv-vWDp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Ridge Regression Models"],"metadata":{"id":"3sY6q1gRr6oV"}},{"cell_type":"code","source":["# define the input features and target variable\n","X = df_cudf_train[[\"danceability\", \"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"valence\",\"tempo\",\"minutes\",\"word_count\",\"words_per_minute\",\"repetition_pct\",\"stopword_pct\",\"profanity_pct\",\"negative_pct\",\"positive_pct\",\"Sentiment\",\"instrumentalnessFlag\",\"livenessFlag\",\"acousticnessFlag\",\"SpeechinessVsWordCount\",\"instrumentalnessFlagVsrepetition_pct\",\"acousticnessFlagnessVsrepetition_pct\",\"acousticnessFlagnessVsloudness\"]]\n","y = df_cudf_train['track_popularity']\n","\n","# split the data into training and testing sets\n","X_test = df_cudf_test[[\"danceability\", \"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"valence\",\"tempo\",\"minutes\",\"word_count\",\"words_per_minute\",\"repetition_pct\",\"stopword_pct\",\"profanity_pct\",\"negative_pct\",\"positive_pct\",\"Sentiment\",\"instrumentalnessFlag\",\"livenessFlag\",\"acousticnessFlag\",\"SpeechinessVsWordCount\",\"instrumentalnessFlagVsrepetition_pct\",\"acousticnessFlagnessVsrepetition_pct\",\"acousticnessFlagnessVsloudness\"]]\n","y_test = df_cudf_test['track_popularity']\n","\n","# create a Ridge regression estimator\n","alpha_range = [0.001, 0.01, 0.1, 1.0]\n","ridge = Ridge(fit_intercept=True, normalize=False, solver='eig')\n","\n","# perform a grid search to find the best alpha value\n","grid_search = GridSearchCV(ridge, {'alpha': alpha_range}, cv=5, refit = True)\n","grid_search.fit(X, y)\n","\n","# print the best alpha value and corresponding score\n","print('Best alpha:', grid_search.best_params_['alpha'])\n","\n","y_pred = grid_search.predict(X_test)\n","\n","# calculate the root mean squared error of the predictions\n","rmse = mean_squared_error(y_test.to_cupy().get(), y_pred, squared=False)\n","mae = mean_absolute_error(y_test.to_cupy().get(), y_pred)\n","\n","# print the root mean squared error\n","print(f\"Root mean squared error: {rmse:.4f}\")\n","print(\"Mean Abosolute Error:\", mae)\n","\n"],"metadata":{"id":"qrsuyb7sTN4q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682895927207,"user_tz":240,"elapsed":1255,"user":{"displayName":"hi","userId":"15692922992261509059"}},"outputId":"f2faf044-89ea-4edd-f8a7-23ca809254d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best alpha: 1.0\n","Root mean squared error: 23.6114\n","Mean Abosolute Error: 19.90170977333556\n"]}]},{"cell_type":"code","source":["# define the input features and target variable\n","X = df_cudf_train[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n","y = df_cudf_train['track_popularity']\n","\n","# split the data into training and testing sets\n","X_test = df_cudf_test[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n","y_test = df_cudf_test['track_popularity']\n","\n","# create a Ridge regression estimator\n","alpha_range = [0.001, 0.01, 0.1, 1.0]\n","ridge = Ridge(fit_intercept=True, normalize=False, solver='eig')\n","\n","# perform a grid search to find the best alpha value\n","grid_search = GridSearchCV(ridge, {'alpha': alpha_range}, cv=5, refit = True)\n","grid_search.fit(X, y)\n","\n","# print the best alpha value and corresponding score\n","print('Best alpha:', grid_search.best_params_['alpha'])\n","\n","y_pred = grid_search.predict(X_test)\n","\n","# calculate the accuracy of the predictions\n","accuracy = mean_squared_error(y_test, y_pred)**0.5\n","\n","# print the accuracy and confusion matrix\n","print(f\"Accuracy: {accuracy:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TD5g6qub9vhb","executionInfo":{"status":"ok","timestamp":1682294137265,"user_tz":240,"elapsed":531,"user":{"displayName":"hi","userId":"15692922992261509059"}},"outputId":"c1743c12-b7f8-43a3-b332-461d33d8ebf0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best alpha: 1.0\n","Accuracy: 23.7215\n"]}]},{"cell_type":"code","source":["# define the input features and target variable\n","X = df_cudf_train_No_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n","y = df_cudf_train_No_Rap['track_popularity']\n","\n","# split the data into training and testing sets\n","X_test = df_cudf_test_No_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n","y_test = df_cudf_test_No_Rap['track_popularity']\n","\n","# create a Ridge regression estimator\n","alpha_range = [0.001, 0.01, 0.1, 1.0]\n","ridge = Ridge(fit_intercept=True, normalize=False, solver='eig')\n","\n","# perform a grid search to find the best alpha value\n","grid_search = GridSearchCV(ridge, {'alpha': alpha_range}, cv=5, refit = True)\n","grid_search.fit(X, y)\n","\n","# print the best alpha value and corresponding score\n","print('Best alpha:', grid_search.best_params_['alpha'])\n","\n","y_pred = grid_search.predict(X_test)\n","\n","# calculate the accuracy of the predictions\n","accuracy = mean_squared_error(y_test, y_pred)**0.5\n","\n","# print the accuracy and confusion matrix\n","print(f\"Accuracy: {accuracy:.4f}\")"],"metadata":{"id":"NGCmFIZLscwd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define the input features and target variable\n","X = df_cudf_train_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"words_per_minute\", \"profanity_pct\"]]\n","y = df_cudf_train_Rap['track_popularity']\n","\n","# split the data into training and testing sets\n","X_test = df_cudf_test_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"words_per_minute\", \"profanity_pct\"]]\n","y_test = df_cudf_test_Rap['track_popularity']\n","\n","# create a Ridge regression estimator\n","alpha_range = [0.001, 0.01, 0.1, 1.0]\n","ridge = Ridge(fit_intercept=True, normalize=False, solver='eig')\n","\n","# perform a grid search to find the best alpha value\n","grid_search = GridSearchCV(ridge, {'alpha': alpha_range}, cv=5, refit = True)\n","grid_search.fit(X, y)\n","\n","# print the best alpha value and corresponding score\n","print('Best alpha:', grid_search.best_params_['alpha'])\n","\n","y_pred = grid_search.predict(X_test)\n","\n","# calculate the accuracy of the predictions\n","accuracy = mean_squared_error(y_test, y_pred)**0.5\n","\n","# print the accuracy and confusion matrix\n","print(f\"Accuracy: {accuracy:.4f}\")"],"metadata":{"id":"jC4xJlBxsc5s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Lasso Models"],"metadata":{"id":"UWonegz7r97C"}},{"cell_type":"code","source":["# define the input features and target variable\n","X = df_cudf_train[[\"danceability\", \"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"valence\",\"tempo\",\"minutes\",\"word_count\",\"words_per_minute\",\"repetition_pct\",\"stopword_pct\",\"profanity_pct\",\"negative_pct\",\"positive_pct\",\"Sentiment\",\"instrumentalnessFlag\",\"livenessFlag\",\"acousticnessFlag\",\"SpeechinessVsWordCount\",\"instrumentalnessFlagVsrepetition_pct\",\"acousticnessFlagnessVsrepetition_pct\",\"acousticnessFlagnessVsloudness\"]]\n","y = df_cudf_train['track_popularity']\n","\n","# split the data into training and testing sets\n","X_test = df_cudf_test[[\"danceability\", \"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"valence\",\"tempo\",\"minutes\",\"word_count\",\"words_per_minute\",\"repetition_pct\",\"stopword_pct\",\"profanity_pct\",\"negative_pct\",\"positive_pct\",\"Sentiment\",\"instrumentalnessFlag\",\"livenessFlag\",\"acousticnessFlag\",\"SpeechinessVsWordCount\",\"instrumentalnessFlagVsrepetition_pct\",\"acousticnessFlagnessVsrepetition_pct\",\"acousticnessFlagnessVsloudness\"]]\n","y_test = df_cudf_test['track_popularity']\n","\n","# create a Ridge regression estimator\n","alpha_range = [0.001, 0.01, 0.1, 1.0]\n","lasso = Lasso()\n","\n","# perform a grid search to find the best alpha value\n","grid_search = GridSearchCV(lasso, {'alpha': alpha_range}, cv=5, refit = True)\n","grid_search.fit(X, y)\n","\n","# print the best alpha value and corresponding score\n","print('Best alpha:', grid_search.best_params_['alpha'])\n","\n","y_pred = grid_search.predict(X_test)\n","\n","# calculate the root mean squared error of the predictions\n","rmse = mean_squared_error(y_test.to_cupy().get(), y_pred, squared=False)\n","mae = mean_absolute_error(y_test.to_cupy().get(), y_pred)\n","\n","# print the root mean squared error\n","print(f\"Root mean squared error: {rmse:.4f}\")\n","print(\"Mean Abosolute Error:\", mae)\n"],"metadata":{"id":"5W8WcC7nDtcU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682896063184,"user_tz":240,"elapsed":2155,"user":{"displayName":"hi","userId":"15692922992261509059"}},"outputId":"7cdf77cf-218c-40c7-b69e-a827461e2427"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best alpha: 0.001\n","Root mean squared error: 23.6128\n","Mean Abosolute Error: 19.893495841040266\n"]}]},{"cell_type":"code","source":["# define the input features and target variable\n","X = df_cudf_train[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n","y = df_cudf_train['track_popularity']\n","\n","# split the data into training and testing sets\n","X = df_cudf_test[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n","y_test = df_cudf_test['track_popularity']\n","\n","# create a Ridge regression estimator\n","alpha_range = [0.001, 0.01, 0.1, 1.0]\n","lasso = Lasso()\n","\n","# perform a grid search to find the best alpha value\n","grid_search = GridSearchCV(lasso, {'alpha': alpha_range}, cv=5, refit = True)\n","grid_search.fit(X, y)\n","\n","# print the best alpha value and corresponding score\n","print('Best alpha:', grid_search.best_params_['alpha'])\n","\n","y_pred = grid_search.predict(X_test)\n","\n","# calculate the accuracy of the predictions\n","accuracy = mean_squared_error(y_test, y_pred)**0.5\n","\n","# print the accuracy and confusion matrix\n","print(f\"Accuracy: {accuracy:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ogyW3yZfDSwm","executionInfo":{"status":"ok","timestamp":1682294137954,"user_tz":240,"elapsed":690,"user":{"displayName":"hi","userId":"15692922992261509059"}},"outputId":"119204b1-9c77-4380-859b-dc2ff4c7894d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best alpha: 0.01\n","Accuracy: 23.7364\n"]}]},{"cell_type":"code","source":["# define the input features and target variable\n","X = df_cudf_train_No_Rap[[\"energy\", \"loudness\", \"speechiness\", \"SpeechinessVsWordCount\", \"tempo\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n","y = df_cudf_train_No_Rap['track_popularity']\n","\n","# split the data into training and testing sets\n","X_test = df_cudf_test_No_Rap[[\"energy\", \"loudness\", \"speechiness\", \"SpeechinessVsWordCount\", \"tempo\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n","y_test = df_cudf_test_No_Rap['track_popularity']\n","\n","# create a Ridge regression estimator\n","alpha_range = [0.001, 0.01, 0.1, 1.0]\n","lasso = Lasso()\n","\n","# perform a grid search to find the best alpha value\n","grid_search = GridSearchCV(lasso, {'alpha': alpha_range}, cv=5, refit = True)\n","grid_search.fit(X, y)\n","\n","# print the best alpha value and corresponding score\n","print('Best alpha:', grid_search.best_params_['alpha'])\n","\n","y_pred = grid_search.predict(X_test)\n","\n","# calculate the accuracy of the predictions\n","accuracy = mean_squared_error(y_test, y_pred)**0.5\n","\n","# print the accuracy and confusion matrix\n","print(f\"Accuracy: {accuracy:.4f}\")\n"],"metadata":{"id":"9bjK0jWjuQK5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define the input features and target variable\n","X = df_cudf_train_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"words_per_minute\", \"profanity_pct\"]]\n","y = df_cudf_train_Rap['track_popularity']\n","\n","# split the data into training and testing sets\n","X_test = df_cudf_test_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"words_per_minute\", \"profanity_pct\"]]\n","y_test = df_cudf_test_Rap['track_popularity']\n","\n","# create a Ridge regression estimator\n","alpha_range = [0.001, 0.01, 0.1, 1.0]\n","lasso = Lasso()\n","\n","# perform a grid search to find the best alpha value\n","grid_search = GridSearchCV(lasso, {'alpha': alpha_range}, cv=5, refit = True)\n","grid_search.fit(X, y)\n","\n","# print the best alpha value and corresponding score\n","print('Best alpha:', grid_search.best_params_['alpha'])\n","\n","y_pred = grid_search.predict(X_test)\n","\n","# calculate the accuracy of the predictions\n","accuracy = mean_squared_error(y_test, y_pred)**0.5\n","\n","# print the accuracy and confusion matrix\n","print(f\"Accuracy: {accuracy:.4f}\")\n"],"metadata":{"id":"RTRA1CLKuQQm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Logistic Regression Models"],"metadata":{"id":"cOHPSlEQryKJ"}},{"cell_type":"code","source":["model = cuml.LogisticRegression(multi_class='multinomial')\n","\n","# define the input features and target variable\n","X = df_cudf_train[[\"danceability\", \"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"valence\",\"tempo\",\"minutes\",\"word_count\",\"words_per_minute\",\"repetition_pct\",\"stopword_pct\",\"profanity_pct\",\"negative_pct\",\"positive_pct\",\"Sentiment\",\"instrumentalnessFlag\",\"livenessFlag\",\"acousticnessFlag\",\"SpeechinessVsWordCount\",\"instrumentalnessFlagVsrepetition_pct\",\"acousticnessFlagnessVsrepetition_pct\",\"acousticnessFlagnessVsloudness\"]]\n","y = df_cudf_train['HitOrMiss']\n","\n","model.fit(X, y)\n","\n","# Make predictions on new data\n","X_test = df_cudf_test[[\"danceability\", \"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"valence\",\"tempo\",\"minutes\",\"word_count\",\"words_per_minute\",\"repetition_pct\",\"stopword_pct\",\"profanity_pct\",\"negative_pct\",\"positive_pct\",\"Sentiment\",\"instrumentalnessFlag\",\"livenessFlag\",\"acousticnessFlag\",\"SpeechinessVsWordCount\",\"instrumentalnessFlagVsrepetition_pct\",\"acousticnessFlagnessVsrepetition_pct\",\"acousticnessFlagnessVsloudness\"]]\n","y_test = df_cudf_test['HitOrMiss']\n","\n","y_pred = model.predict(X_test)\n","\n","# calculate the accuracy of the predictions\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","# print the accuracy\n","print(f\"Accuracy: {accuracy:.4f}\")\n","\n","# calculate the f1 score of the model\n","f1 = f1_score(y_test.to_cupy().get(), y_pred.to_cupy().get(), average=None)\n","print(f\"F1 scores for each class: {f1}\")\n"],"metadata":{"id":"A0SFQwSm4E5a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682894355848,"user_tz":240,"elapsed":1433,"user":{"displayName":"hi","userId":"15692922992261509059"}},"outputId":"23f0eb22-ae5e-4528-e37d-97c63fd96173"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[I] [22:39:12.988138] Unused keyword parameter: multi_class during cuML estimator initialization\n","[W] [22:39:14.059236] L-BFGS: max iterations reached\n","[W] [22:39:14.061987] Maximum iterations reached before solver is converged. To increase model accuracy you can increase the number of iterations (max_iter) or improve the scaling of the input data.\n","Accuracy: 0.7503\n","F1 scores for each class: [0.         0.85708834 0.12658228]\n"]}]},{"cell_type":"code","source":["model = cuml.LogisticRegression(multi_class='multinomial')\n","\n","# define the input features and target variable\n","X = df_cudf_train[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n","y = df_cudf_train['HitOrMiss']\n","\n","model.fit(X, y)\n","\n","# Make predictions on new data\n","X_test = df_cudf_test[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n","y_test = df_cudf_test['HitOrMiss']\n","\n","y_pred = model.predict(X_test)\n","\n","# calculate the accuracy of the predictions\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","# print the accuracy\n","print(f\"Accuracy: {accuracy:.4f}\")\n","\n","# calculate the f1 score of the model\n","f1 = f1_score(y_test.to_cupy().get(), y_pred.to_cupy().get(), average=None)\n","print(f\"F1 scores for each class: {f1}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C6jOrIGkio-K","executionInfo":{"status":"ok","timestamp":1682294135174,"user_tz":240,"elapsed":479,"user":{"displayName":"hi","userId":"15692922992261509059"}},"outputId":"5c349515-6360-4cd0-d209-4ce0c9693c03"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[I] [23:55:33.946950] Unused keyword parameter: multi_class during cuML estimator initialization\n","[W] [23:55:34.580594] L-BFGS: max iterations reached\n","[W] [23:55:34.582082] Maximum iterations reached before solver is converged. To increase model accuracy you can increase the number of iterations (max_iter) or improve the scaling of the input data.\n","Accuracy: 0.7273333333333334\n"]}]},{"cell_type":"code","source":["model = cuml.LogisticRegression(multi_class='multinomial')\n","\n","# define the input features and target variable\n","X = df_cudf_train_No_Rap[[\"energy\", \"loudness\", \"speechiness\", \"SpeechinessVsWordCount\", \"tempo\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n","y = df_cudf_train_No_Rap['HitOrMiss']\n","\n","model.fit(X, y)\n","\n","# Make predictions on new data\n","X_test = df_cudf_test_No_Rap[[\"energy\", \"loudness\", \"speechiness\", \"SpeechinessVsWordCount\", \"tempo\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n","y_test = df_cudf_test_No_Rap['HitOrMiss']\n","\n","y_pred = model.predict(X_test)\n","\n","# calculate the accuracy of the predictions\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","# print the accuracy\n","print(f\"Accuracy: {accuracy:.4f}\")\n","\n","# calculate the f1 score of the model\n","f1 = f1_score(y_test.to_cupy().get(), y_pred.to_cupy().get(), average=None)\n","print(f\"F1 scores for each class: {f1}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y_93v3s0jp5H","executionInfo":{"status":"ok","timestamp":1682294135700,"user_tz":240,"elapsed":528,"user":{"displayName":"hi","userId":"15692922992261509059"}},"outputId":"470a24ba-3529-48c8-9b2a-27e7e2ebc22d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[I] [23:55:34.624260] Unused keyword parameter: multi_class during cuML estimator initialization\n","Accuracy: 0.694\n"]}]},{"cell_type":"code","source":["model = cuml.LogisticRegression(multi_class='multinomial')\n","\n","# define the input features and target variable\n","X = df_cudf_train_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"words_per_minute\", \"profanity_pct\"]]\n","y = df_cudf_train_Rap['HitOrMiss']\n","\n","model.fit(X, y)\n","\n","# Make predictions on new data\n","X_test = df_cudf_test_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"words_per_minute\", \"profanity_pct\"]]\n","y_test = df_cudf_test_Rap['HitOrMiss']\n","\n","y_pred = model.predict(X_test)\n","\n","# calculate the accuracy of the predictions\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","# print the accuracy\n","print(f\"Accuracy: {accuracy:.4f}\")\n","\n","# calculate the f1 score of the model\n","f1 = f1_score(y_test.to_cupy().get(), y_pred.to_cupy().get(), average=None)\n","print(f\"F1 scores for each class: {f1}\")\n"],"metadata":{"id":"-kqCUG_SugFF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Random Forest Models"],"metadata":{"id":"44t0-M0msAUB"}},{"cell_type":"code","source":["# define the input features and target variable\n","X = df_cudf_train[[\"danceability\", \"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"valence\",\"tempo\",\"minutes\",\"word_count\",\"words_per_minute\",\"repetition_pct\",\"stopword_pct\",\"profanity_pct\",\"negative_pct\",\"positive_pct\",\"Sentiment\",\"instrumentalnessFlag\",\"livenessFlag\",\"acousticnessFlag\",\"SpeechinessVsWordCount\",\"instrumentalnessFlagVsrepetition_pct\",\"acousticnessFlagnessVsrepetition_pct\",\"acousticnessFlagnessVsloudness\"]]\n","y = df_cudf_train['HitOrMiss']\n","\n","# split the data into training and testing sets\n","X_test = df_cudf_test[[\"danceability\", \"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"valence\",\"tempo\",\"minutes\",\"word_count\",\"words_per_minute\",\"repetition_pct\",\"stopword_pct\",\"profanity_pct\",\"negative_pct\",\"positive_pct\",\"Sentiment\",\"instrumentalnessFlag\",\"livenessFlag\",\"acousticnessFlag\",\"SpeechinessVsWordCount\",\"instrumentalnessFlagVsrepetition_pct\",\"acousticnessFlagnessVsrepetition_pct\",\"acousticnessFlagnessVsloudness\"]]\n","y_test = df_cudf_test['HitOrMiss']\n","\n","# define a range of hyperparameters to search over\n","param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, 15]}\n","\n","# initialize a Random Forest classifier estimator\n","rf = RandomForestClassifier(max_features='auto')\n","\n","# perform grid search over the hyperparameters\n","grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n","grid_search.fit(X.to_cupy().get(), y.to_cupy().get())\n","\n","# print the best performing hyperparameters and their performance\n","print(\"Best hyperparameters:\", grid_search.best_params_)\n","print(\"Average score:\", grid_search.best_score_)\n","print(\"Standard deviation:\", grid_search.cv_results_['std_test_score'][grid_search.best_index_])\n","\n","# extract the best performing random forest\n","best_rf = grid_search.best_estimator_\n","\n","# train the best performing random forest on the entire dataset\n","best_rf.fit(X, y)\n","\n","# use the best performing random forest for prediction\n","predictions = best_rf.predict(X_test)\n","\n","# calculate the accuracy of the predictions\n","accuracy = accuracy_score(y_test, predictions)\n","\n","# print the accuracy and confusion matrix\n","print(f\"Accuracy: {accuracy:.4f}\")\n","\n","# calculate the f1 score of the model\n","f1 = f1_score(y_test.to_cupy().get(), predictions.to_cupy().get(), average=None)\n","print(f\"F1 scores for each class: {f1}\")\n"],"metadata":{"id":"6z5NDFAqvWIq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define the input features and target variable\n","X = df_cudf_train[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n","y = df_cudf_train['HitOrMiss']\n","\n","# split the data into training and testing sets\n","X_test = df_cudf_test[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n","y_test = df_cudf_test['HitOrMiss']\n","\n","# define a range of hyperparameters to search over\n","param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, 15]}\n","\n","# initialize a Random Forest classifier estimator\n","rf = RandomForestClassifier(max_features='auto')\n","\n","# perform grid search over the hyperparameters\n","grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n","grid_search.fit(X.to_cupy().get(), y.to_cupy().get())\n","\n","# print the best performing hyperparameters and their performance\n","print(\"Best hyperparameters:\", grid_search.best_params_)\n","print(\"Average score:\", grid_search.best_score_)\n","print(\"Standard deviation:\", grid_search.cv_results_['std_test_score'][grid_search.best_index_])\n","\n","# extract the best performing random forest\n","best_rf = grid_search.best_estimator_\n","\n","# train the best performing random forest on the entire dataset\n","best_rf.fit(X, y)\n","\n","# use the best performing random forest for prediction\n","predictions = best_rf.predict(X_test)\n","\n","# calculate the accuracy of the predictions\n","accuracy = accuracy_score(y_test, predictions)\n","\n","# print the accuracy and confusion matrix\n","print(f\"Accuracy: {accuracy:.4f}\")\n","\n","# calculate the f1 score of the model\n","f1 = f1_score(y_test.to_cupy().get(), predictions.to_cupy().get(), average=None)\n","print(f\"F1 scores for each class: {f1}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T9rQBhbRAa4c","executionInfo":{"status":"ok","timestamp":1682894591104,"user_tz":240,"elapsed":32303,"user":{"displayName":"hi","userId":"15692922992261509059"}},"outputId":"8ebecd03-8f3d-4a46-e20a-97f98c67a255"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n","  ret = func(*args, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters: {'max_depth': 10, 'n_estimators': 200}\n","Average score: 0.7387680423084917\n","Standard deviation: 0.0019664105476475654\n","Accuracy: 0.7503\n","F1 scores for each class: [0.01164483 0.85708827 0.10126582]\n"]}]},{"cell_type":"code","source":["# define the input features and target variable\n","X = df_cudf_train_No_Rap[[\"energy\", \"loudness\", \"speechiness\", \"SpeechinessVsWordCount\", \"tempo\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n","y = df_cudf_train_No_Rap['HitOrMiss']\n","\n","# split the data into training and testing sets\n","X_test = df_cudf_test_No_Rap[[\"energy\", \"loudness\", \"speechiness\", \"SpeechinessVsWordCount\", \"tempo\", \"minutes\", \"word_count\", \"words_per_minute\", \"profanity_pct\"]]\n","y_test = df_cudf_test_No_Rap['HitOrMiss']\n","\n","# define a range of hyperparameters to search over\n","param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, 15]}\n","\n","# initialize a Random Forest classifier estimator\n","rf = RandomForestClassifier(max_features='auto')\n","\n","# perform grid search over the hyperparameters\n","grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n","grid_search.fit(X.to_cupy().get(), y.to_cupy().get())\n","\n","# print the best performing hyperparameters and their performance\n","print(\"Best hyperparameters:\", grid_search.best_params_)\n","print(\"Average score:\", grid_search.best_score_)\n","print(\"Standard deviation:\", grid_search.cv_results_['std_test_score'][grid_search.best_index_])\n","\n","# extract the best performing random forest\n","best_rf = grid_search.best_estimator_\n","\n","# train the best performing random forest on the entire dataset\n","best_rf.fit(X, y)\n","\n","# use the best performing random forest for prediction\n","predictions = best_rf.predict(X_test)\n","\n","# calculate the accuracy of the predictions\n","accuracy = accuracy_score(y_test, predictions)\n","\n","# print the accuracy and confusion matrix\n","print(f\"Accuracy: {accuracy:.4f}\")\n","\n","# calculate the f1 score of the model\n","f1 = f1_score(y_test.to_cupy().get(), predictions.to_cupy().get(), average=None)\n","print(f\"F1 scores for each class: {f1}\")\n"],"metadata":{"id":"ja_o2JYybZ7o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define the input features and target variable\n","X = df_cudf_train_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"words_per_minute\", \"profanity_pct\"]]\n","y = df_cudf_train_Rap['HitOrMiss']\n","\n","# split the data into training and testing sets\n","X_test = df_cudf_test_Rap[[\"energy\", \"loudness\", \"SpeechinessVsWordCount\", \"minutes\", \"words_per_minute\", \"profanity_pct\"]]\n","y_test = df_cudf_test_Rap['HitOrMiss']\n","\n","# define a range of hyperparameters to search over\n","param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, 15]}\n","\n","# initialize a Random Forest classifier estimator\n","rf = RandomForestClassifier(max_features='auto')\n","\n","# perform grid search over the hyperparameters\n","grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n","grid_search.fit(X.to_cupy().get(), y.to_cupy().get())\n","\n","# print the best performing hyperparameters and their performance\n","print(\"Best hyperparameters:\", grid_search.best_params_)\n","print(\"Average score:\", grid_search.best_score_)\n","print(\"Standard deviation:\", grid_search.cv_results_['std_test_score'][grid_search.best_index_])\n","\n","# extract the best performing random forest\n","best_rf = grid_search.best_estimator_\n","\n","# train the best performing random forest on the entire dataset\n","best_rf.fit(X, y)\n","\n","# use the best performing random forest for prediction\n","predictions = best_rf.predict(X_test)\n","\n","# calculate the accuracy of the predictions\n","accuracy = accuracy_score(y_test, predictions)\n","\n","# print the accuracy and confusion matrix\n","print(f\"Accuracy: {accuracy:.4f}\")\n","\n","# calculate the f1 score of the model\n","f1 = f1_score(y_test.to_cupy().get(), predictions.to_cupy().get(), average=None)\n","print(f\"F1 scores for each class: {f1}\")\n"],"metadata":{"id":"GqB7vW_GYrag"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# SVM Model"],"metadata":{"id":"4BlZNxwusIrr"}},{"cell_type":"code","source":["# define the input features and target variable\n","X = df_cudf_train[[\"danceability\", \"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"valence\",\"tempo\",\"minutes\",\"word_count\",\"words_per_minute\",\"repetition_pct\",\"stopword_pct\",\"profanity_pct\",\"negative_pct\",\"positive_pct\",\"Sentiment\",\"instrumentalnessFlag\",\"livenessFlag\",\"acousticnessFlag\",\"SpeechinessVsWordCount\",\"instrumentalnessFlagVsrepetition_pct\",\"acousticnessFlagnessVsrepetition_pct\",\"acousticnessFlagnessVsloudness\"]]\n","y = df_cudf_train['HitOrMiss']\n","\n","# split the data into training and testing sets\n","X_test = df_cudf_test[[\"danceability\", \"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"valence\",\"tempo\",\"minutes\",\"word_count\",\"words_per_minute\",\"repetition_pct\",\"stopword_pct\",\"profanity_pct\",\"negative_pct\",\"positive_pct\",\"Sentiment\", \"instrumentalnessFlag\",\"livenessFlag\",\"acousticnessFlag\",\"SpeechinessVsWordCount\",\"instrumentalnessFlagVsrepetition_pct\",\"acousticnessFlagnessVsrepetition_pct\",\"acousticnessFlagnessVsloudness\"]]\n","y_test = df_cudf_test['HitOrMiss']\n","\n","# Create an SVC classifier object\n","svc = SVC(C=1.0, gamma=0.1, kernel='linear')\n","\n","# Perform grid search cross-validation to find the best hyperparameters\n","svc.fit(X.to_cupy().get(), y.to_cupy().get())\n","\n","# Make predictions on test data using the best model\n","y_pred = svc.predict(X_test)\n","\n","# Calculate accuracy score\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","print('svc accuracy:', accuracy)\n","\n","# calculate the f1 score of the model\n","f1 = f1_score(y_test.to_cupy().get(), y_pred.to_cupy().get(), average=None)\n","print(f\"F1 scores for each class: {f1}\")"],"metadata":{"id":"UcWjiATSfFJf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682899208019,"user_tz":240,"elapsed":3063315,"user":{"displayName":"hi","userId":"15692922992261509059"}},"outputId":"0cadc2fe-80c8-4e3f-b5d7-865f1cf4296b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[W] [23:09:03.407456] SVC with the linear kernel can be much faster using the specialized solver provided by LinearSVC. Consider switching to LinearSVC if tranining takes too long.\n","svc accuracy: 0.749666690826416\n","F1 scores for each class: [0.         0.85692513 0.        ]\n"]}]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["RZ7GEuUIrlWg","gMq5Cu5Prr7U"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU","gpuClass":"premium"},"nbformat":4,"nbformat_minor":0}